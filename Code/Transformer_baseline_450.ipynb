{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed81ef80-47dd-4cae-a0da-2759ad96cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import time as time\n",
    "\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from pylab import rcParams\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset\n",
    "\n",
    "from utils import (\n",
    "    load_and_partition_data,\n",
    "    split_sequence\n",
    ")\n",
    "\n",
    "import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3aa4fb-5706-4def-b88f-9ac2ec924557",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa4ab5f0-0d3d-44a2-bd8d-0eabb6d0201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"sales_train_validation.csv\")\n",
    "sell_prices = pd.read_csv(\"sell_prices.csv\")\n",
    "calendar = pd.read_csv(\"calendar.csv\")\n",
    "# validation contains 28 more dates\n",
    "validation = pd.read_csv(\"sales_train_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa99612-2571-46ff-8636-c9c00093cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cols = [c for c in train.columns if 'd_' in c]\n",
    "dates = calendar[calendar.d.isin(d_cols)]['date']\n",
    "dates_list = [datetime.strptime(date, '%Y-%m-%d').date() for date in dates]\n",
    "df_sales = train[d_cols].T\n",
    "df_sales.columns = train['id'].values\n",
    "df_sales = pd.DataFrame(df_sales).set_index([dates_list])\n",
    "df_sales.index = pd.to_datetime(df_sales.index)\n",
    "df_sales.columns = [i for i in range(len(df_sales.columns))]\n",
    "\n",
    "d_cols = [c for c in validation.columns if 'd_' in c]\n",
    "dates = calendar[calendar.d.isin(d_cols)]['date']\n",
    "dates_list = [datetime.strptime(date, '%Y-%m-%d').date() for date in dates]\n",
    "df_validation = validation[d_cols].T\n",
    "df_validation.columns = validation['id'].values\n",
    "df_validation = pd.DataFrame(df_validation).set_index([dates_list])\n",
    "df_validation.index = pd.to_datetime(df_validation.index)\n",
    "df_validation.columns = [i for i in range(len(df_validation.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b298b9e-b84d-45e5-bb7a-95e115fdf6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1345\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4383a5bc-433e-4bf3-830b-35229dee6ea8",
   "metadata": {},
   "source": [
    "# Running Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9ef509-eb4a-4e4b-901c-2311e05dcc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8cf3f00-ff7b-4da2-a954-7e19fe6fb762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.pe[:, : x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerWithPE(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, in_dim: int, out_dim: int, embed_dim: int, num_heads: int, num_layers: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim)\n",
    "        self.encoder_embedding = torch.nn.Linear(\n",
    "            in_features=in_dim, out_features=embed_dim\n",
    "        )\n",
    "        self.decoder_embedding = torch.nn.Linear(\n",
    "            in_features=out_dim, out_features=embed_dim\n",
    "        )\n",
    "        self.output_layer = torch.nn.Linear(in_features=embed_dim, out_features=out_dim)\n",
    "        self.transformer = torch.nn.Transformer(\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            d_model=embed_dim,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, src: torch.Tensor, tgt: torch.Tensor) -> torch.Tensor:\n",
    "        # if self.train:\n",
    "        # Add noise to decoder inputs during training\n",
    "        # tgt = tgt + torch.normal(0, 0.1, size=tgt.shape).to(tgt.device)\n",
    "\n",
    "        # Embed encoder input and add positional encoding.\n",
    "        # [bs, src_seq_len, embed_dim]\n",
    "        src = self.encoder_embedding(src)\n",
    "        src = self.positional_encoding(src)\n",
    "\n",
    "        # Generate mask to avoid attention to future outputs.\n",
    "        # [tgt_seq_len, tgt_seq_len]\n",
    "        tgt_mask = torch.nn.Transformer.generate_square_subsequent_mask(tgt.shape[1])\n",
    "        # Embed decoder input and add positional encoding.\n",
    "        # [bs, tgt_seq_len, embed_dim]\n",
    "        tgt = self.decoder_embedding(tgt)\n",
    "        tgt = self.positional_encoding(tgt)\n",
    "\n",
    "        # Get prediction from transformer and map to output dimension.\n",
    "        # [bs, tgt_seq_len, embed_dim]\n",
    "        pred = self.transformer(src, tgt, tgt_mask=tgt_mask.to(device))\n",
    "        pred = self.output_layer(pred)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def infer(self, src: torch.Tensor, tgt_len: int) -> torch.Tensor:\n",
    "        output = torch.zeros((src.shape[0], tgt_len + 1, src.shape[2])).to(src.device)\n",
    "        output[:, 0] = src[:, -1]\n",
    "        for i in range(tgt_len):\n",
    "            output[:, i + 1] = self.forward(src, output)[:, i]\n",
    "\n",
    "        return output[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a53bd513-b277-4981-b9ec-9c30b827b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_batch_size = 32\n",
    "optimal_d_model = 64\n",
    "optimal_num_head = 4\n",
    "optimal_num_layer = 2\n",
    "optimal_sequence_length = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024fc23b-83c0-4485-ae1c-4ad80eff435e",
   "metadata": {},
   "source": [
    "## Batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45779954-e469-477e-b01a-573e22190929",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = pd.read_csv(\"Baseline_LSTM_Results_1.csv\")\n",
    "results1 = results1.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ef0399-18be-4df6-80b4-f4110e69fe1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 2 test rmse, test r2, time taken: 1.0126758141651615, -0.1372017635113678, 51.0062575340271\n",
      "Item 268 test rmse, test r2, time taken: 0.6210680250798335, -0.011400620578015497, 53.606062173843384\n",
      "Item 345 test rmse, test r2, time taken: 4.863219436457825, -0.8767518397893395, 50.29061532020569\n",
      "Item 380 test rmse, test r2, time taken: 0.4786438375494548, -0.22186625719503383, 29.99994730949402\n",
      "Item 465 test rmse, test r2, time taken: 0.5221294560828535, -0.1368799384305912, 44.63188815116882\n",
      "Item 478 test rmse, test r2, time taken: 0.8366258770818243, -0.06347907137809816, 27.712098360061646\n",
      "Item 520 test rmse, test r2, time taken: 0.5853080087781909, -0.10076641258063246, 28.49231743812561\n",
      "Item 529 test rmse, test r2, time taken: 0.8218823979722413, -0.2639252746055738, 63.9230740070343\n",
      "Item 569 test rmse, test r2, time taken: 1.1349450317936016, -0.12708769704385725, 21.71237063407898\n",
      "Item 576 test rmse, test r2, time taken: 1.0803582313798283, -0.22334805342026454, 29.61724615097046\n",
      "Item 657 test rmse, test r2, time taken: 4.502614999763182, -0.1541139122492332, 76.74131798744202\n",
      "Item 773 test rmse, test r2, time taken: 1.1400035562914803, -0.07478138918993893, 62.41358733177185\n",
      "Item 783 test rmse, test r2, time taken: 0.9386175895563966, -0.03399152076187706, 38.65834856033325\n",
      "Item 812 test rmse, test r2, time taken: 0.37625694403903787, -0.027688164287731354, 56.24963641166687\n",
      "Item 888 test rmse, test r2, time taken: 1.821555877310232, -0.12710727829468937, 42.28406500816345\n",
      "Item 892 test rmse, test r2, time taken: 6.688226123789071, -1.9862207976345965, 97.94781279563904\n",
      "Item 998 test rmse, test r2, time taken: 1.1649990995906931, -0.09471476872936924, 23.970656156539917\n",
      "Item 1073 test rmse, test r2, time taken: 0.9044836503289225, 0.07180450334230282, 164.5977282524109\n",
      "Item 1085 test rmse, test r2, time taken: 1.3976678696450304, -0.023746505006051688, 20.159926891326904\n",
      "Item 1087 test rmse, test r2, time taken: 1.1998844293538908, -0.0270632873010328, 55.75922632217407\n",
      "Item 1102 test rmse, test r2, time taken: 0.1884369610138522, -0.031061289203358156, 23.347931623458862\n",
      "Item 1159 test rmse, test r2, time taken: 0.4417633264201866, -0.006588104412799112, 31.275959968566895\n",
      "Item 1163 test rmse, test r2, time taken: 0.9330740863388118, -0.305108536267791, 18.358065605163574\n",
      "Item 1170 test rmse, test r2, time taken: 1.6503329806086418, 0.005448731086386105, 60.00379467010498\n",
      "Item 1172 test rmse, test r2, time taken: 0.7781118905848711, -0.0056761898036794545, 18.197676420211792\n",
      "Item 1220 test rmse, test r2, time taken: 0.7289473016126625, -0.22887760509218702, 47.85499453544617\n",
      "Item 1235 test rmse, test r2, time taken: 1.1110034780793339, 0.003384425344354347, 28.870899438858032\n",
      "Item 1236 test rmse, test r2, time taken: 1.268827771782852, -0.031193095528423864, 38.157113790512085\n",
      "Item 1244 test rmse, test r2, time taken: 0.6437164946456423, -0.06864080781393644, 17.3965904712677\n",
      "Item 1343 test rmse, test r2, time taken: 1.1156555140241955, -0.1255303173731397, 24.046794176101685\n",
      "Item 1383 test rmse, test r2, time taken: 0.6800320527699916, 0.0012237555070474526, 68.76349186897278\n",
      "Item 1453 test rmse, test r2, time taken: 0.4111908799355681, -0.011886295861636587, 20.652864694595337\n",
      "Item 1464 test rmse, test r2, time taken: 0.9685809828619599, -0.006168140032397851, 121.13068151473999\n",
      "Item 1509 test rmse, test r2, time taken: 0.5932258545162359, -0.27732805991551057, 17.578502893447876\n",
      "Item 1573 test rmse, test r2, time taken: 0.3095181420228492, -0.0014448067888117588, 43.8648784160614\n",
      "Item 1644 test rmse, test r2, time taken: 0.6055511223463549, -0.015853903998392926, 37.08383584022522\n",
      "Item 1663 test rmse, test r2, time taken: 0.36669790857186996, -0.09815007523303199, 36.06836748123169\n",
      "Item 1741 test rmse, test r2, time taken: 0.8948490225711477, -0.33006725039425033, 16.889771699905396\n",
      "Item 1757 test rmse, test r2, time taken: 0.40877134375382174, -1.301523553576267e-05, 30.48906111717224\n",
      "Item 1776 test rmse, test r2, time taken: 0.8233254866196926, -0.006526605726064227, 22.723459720611572\n",
      "Item 1786 test rmse, test r2, time taken: 0.9720085696696087, -0.04769974124009657, 20.24424171447754\n",
      "Item 1787 test rmse, test r2, time taken: 0.608950014076898, -0.02728966007454181, 26.195707321166992\n",
      "Item 1790 test rmse, test r2, time taken: 1.2719171018306683, -0.1625427326494886, 33.032715797424316\n",
      "Item 1792 test rmse, test r2, time taken: 1.4562672628143576, -0.9355530187938759, 20.643627643585205\n",
      "Item 1873 test rmse, test r2, time taken: 0.6121193941448494, 0.06743784219811455, 78.69670867919922\n",
      "Item 1950 test rmse, test r2, time taken: 0.73335686823867, -0.0063122678166553925, 30.796444416046143\n",
      "Item 2054 test rmse, test r2, time taken: 0.6016992911165027, -0.043532929974999135, 59.759825468063354\n",
      "Item 2066 test rmse, test r2, time taken: 1.701394105787011, -0.41136669907594325, 19.97333574295044\n",
      "Item 2068 test rmse, test r2, time taken: 1.5159478012840444, -0.017339709313865415, 27.050211191177368\n",
      "Item 2076 test rmse, test r2, time taken: 1.6169094264895523, -1.5367407639617392, 24.192485809326172\n",
      "Item 2134 test rmse, test r2, time taken: 0.9749747263326533, -0.007096435294792869, 20.312628746032715\n",
      "Item 2151 test rmse, test r2, time taken: 3.9649352999293828, -0.014573440498754309, 18.992610454559326\n",
      "Item 2210 test rmse, test r2, time taken: 1.7414300369698197, -0.0792290520880592, 44.346683502197266\n",
      "Item 2215 test rmse, test r2, time taken: 0.9202280655811227, -0.2866407733790879, 48.37617874145508\n",
      "Item 2396 test rmse, test r2, time taken: 1.4522193197507798, 0.006364358844101248, 30.57566809654236\n",
      "Item 2414 test rmse, test r2, time taken: 2.7814771706317245, -0.11171304189597553, 24.829680919647217\n",
      "Item 2432 test rmse, test r2, time taken: 3.2298607067659715, -0.4251068383214587, 45.861122608184814\n",
      "Item 2463 test rmse, test r2, time taken: 1.4120934950783226, -0.10169295451200178, 92.83368968963623\n",
      "Item 2466 test rmse, test r2, time taken: 0.864789605198102, -0.08779790728536607, 49.80444526672363\n",
      "Item 2508 test rmse, test r2, time taken: 0.49290468419269323, -0.05820412064496283, 38.6928813457489\n",
      "Item 2512 test rmse, test r2, time taken: 6.97399651665362, -1.470431868662696, 65.92223405838013\n",
      "Item 2523 test rmse, test r2, time taken: 3.8631188065732345, -1.7115111333350295, 36.71729588508606\n",
      "Item 2557 test rmse, test r2, time taken: 1.6190969500914123, -0.7126969567462711, 48.04274940490723\n",
      "Item 2572 test rmse, test r2, time taken: 4.647396331357158, -0.3912629567002044, 45.44657325744629\n",
      "Item 2601 test rmse, test r2, time taken: 2.88198882240284, 0.0017179357957000096, 22.4164137840271\n",
      "Item 2627 test rmse, test r2, time taken: 3.0954114023730526, -1.0802969404469205, 17.76754403114319\n",
      "Item 2690 test rmse, test r2, time taken: 0.0015317862988131798, 0.0, 36.42604398727417\n",
      "Item 2716 test rmse, test r2, time taken: 1.0130565767728443, -0.30617916258163547, 35.942893505096436\n",
      "Item 2731 test rmse, test r2, time taken: 0.6371980649252574, -0.09013957935781569, 31.589354276657104\n",
      "Item 2746 test rmse, test r2, time taken: 2.3173647446731556, -0.2256828582607271, 19.623591899871826\n",
      "Item 2836 test rmse, test r2, time taken: 1.0307279942864729, -0.41653359760775355, 23.510582208633423\n",
      "Item 2880 test rmse, test r2, time taken: 1.9185275663211772, -0.7467956718060889, 29.716395378112793\n",
      "Item 2901 test rmse, test r2, time taken: 0.8930797906035414, -0.010196681275316477, 24.766889810562134\n",
      "Item 2913 test rmse, test r2, time taken: 1.4160624640215633, -0.0007018428876408578, 18.650865077972412\n",
      "Item 2926 test rmse, test r2, time taken: 1.5398511004439341, -0.25267848156745387, 19.12937831878662\n",
      "Item 2937 test rmse, test r2, time taken: 7.476208878499223, 0.5025523587104099, 44.85065579414368\n",
      "Item 2950 test rmse, test r2, time taken: 1.98749149008071, -0.012388355588198952, 17.800196647644043\n",
      "Item 2962 test rmse, test r2, time taken: 8.537381737461466, -0.8498371484903109, 59.39122557640076\n",
      "Item 2980 test rmse, test r2, time taken: 1.0809818658160208, -0.0012252313343161791, 22.193862438201904\n",
      "Item 2983 test rmse, test r2, time taken: 1.405305187202349, -0.3923633207153041, 49.37470293045044\n",
      "Item 2990 test rmse, test r2, time taken: 2.981208118798431, -0.1454676719563226, 40.1739444732666\n",
      "Item 3033 test rmse, test r2, time taken: 1.255749287859333, -0.010044541490220604, 23.650126457214355\n",
      "Item 3036 test rmse, test r2, time taken: 1.0543252143022652, -0.004027303560596662, 18.345800638198853\n",
      "Item 3102 test rmse, test r2, time taken: 0.42991006392210895, -0.09773460485019148, 33.636614084243774\n",
      "Item 3205 test rmse, test r2, time taken: 1.140970798976999, -0.05110449172881304, 48.998549461364746\n",
      "Item 3318 test rmse, test r2, time taken: 2.3046088994330782, -0.0040989121310286425, 38.9388689994812\n",
      "Item 3336 test rmse, test r2, time taken: 1.1538038872380179, -0.46588555281061783, 16.85131549835205\n",
      "Item 3381 test rmse, test r2, time taken: 3.4908484245613316, -0.14609426763887567, 27.209893941879272\n",
      "Item 3451 test rmse, test r2, time taken: 0.8406913619215545, -0.059467268358436076, 26.994853734970093\n",
      "Item 3462 test rmse, test r2, time taken: 0.35165976359273954, -0.009927479529161731, 30.69863200187683\n",
      "Item 3483 test rmse, test r2, time taken: 0.001744091573919691, 0.0, 29.37804651260376\n",
      "Item 3568 test rmse, test r2, time taken: 0.41077839335686334, -0.009857164457215406, 21.799695014953613\n",
      "Item 3651 test rmse, test r2, time taken: 1.3484358824631686, -0.5981289170690047, 18.060356378555298\n",
      "Item 3681 test rmse, test r2, time taken: 1.4530439996400601, -0.02178277905786863, 32.620854139328\n",
      "Item 3690 test rmse, test r2, time taken: 2.0389730620462485, -0.09083344706700158, 58.839203119277954\n",
      "Item 3738 test rmse, test r2, time taken: 1.778859264107025, -0.10603779790259438, 20.51812720298767\n",
      "Item 3745 test rmse, test r2, time taken: 2.089629187297738, -0.7116876550393898, 17.08917808532715\n",
      "Item 3848 test rmse, test r2, time taken: 0.8276238191926002, -0.1674121084748641, 24.75810742378235\n",
      "Item 3893 test rmse, test r2, time taken: 0.9188537513848842, -0.02943250028664779, 48.43406558036804\n",
      "Item 3915 test rmse, test r2, time taken: 0.7272441066747687, -0.008868731638576488, 42.63304257392883\n",
      "Item 4017 test rmse, test r2, time taken: 2.0974731041597217, 0.05321865402800985, 23.193042993545532\n",
      "Item 4065 test rmse, test r2, time taken: 1.6596316205817354, -0.17105838339004897, 16.624295711517334\n",
      "Item 4155 test rmse, test r2, time taken: 0.610933889539521, -0.0021244192880272017, 28.024818897247314\n",
      "Item 4178 test rmse, test r2, time taken: 0.7687377600195847, -0.10575386884263471, 66.43107104301453\n",
      "Item 4209 test rmse, test r2, time taken: 0.700811675083447, -0.06074768893576099, 75.03617811203003\n",
      "Item 4259 test rmse, test r2, time taken: 0.6086256558170003, -0.1902186398042629, 59.6762421131134\n",
      "Item 4278 test rmse, test r2, time taken: 0.42113605247545743, -0.20910235270065436, 43.59754300117493\n",
      "Item 4280 test rmse, test r2, time taken: 0.9968497595480668, -0.15932768362954497, 42.38819122314453\n",
      "Item 4318 test rmse, test r2, time taken: 0.4976032903837701, -0.011070224619748048, 64.02652502059937\n",
      "Item 4323 test rmse, test r2, time taken: 0.925244540551018, -0.15718056637665545, 108.99811792373657\n",
      "Item 4424 test rmse, test r2, time taken: 0.6119071257259471, -0.29318669217235693, 20.36602282524109\n",
      "Item 4523 test rmse, test r2, time taken: 0.47957277287971667, -0.18626443998836573, 39.81079459190369\n",
      "Item 4573 test rmse, test r2, time taken: 0.5390460314369947, -0.0035566926090362383, 18.87194299697876\n",
      "Item 4578 test rmse, test r2, time taken: 1.5102992004578975, -0.22570725231292088, 26.02345895767212\n",
      "Item 4622 test rmse, test r2, time taken: 0.312437089846539, -0.47176302168521245, 25.90778422355652\n",
      "Item 4712 test rmse, test r2, time taken: 1.3744381857531098, -0.0007020107714454937, 23.199188709259033\n",
      "Item 4764 test rmse, test r2, time taken: 2.591233353591581, -0.040553546062092716, 22.30017614364624\n",
      "Item 4822 test rmse, test r2, time taken: 1.3622389398075678, -0.10889087228383265, 26.38388466835022\n",
      "Item 4903 test rmse, test r2, time taken: 0.693697639620144, -0.0841197400236049, 44.108314037323\n",
      "Item 4937 test rmse, test r2, time taken: 2.2940495319004706, 0.06800813377609882, 69.56180572509766\n",
      "Item 4979 test rmse, test r2, time taken: 0.8291923939967629, -0.48497812834565535, 59.583247661590576\n",
      "Item 5008 test rmse, test r2, time taken: 0.976002310035386, -0.2064993848278147, 27.026707887649536\n",
      "Item 5014 test rmse, test r2, time taken: 1.3935820712321962, -0.16494541360344117, 29.759368658065796\n",
      "Item 5059 test rmse, test r2, time taken: 2.276106445651437, -1.4720863497978325, 73.13557481765747\n",
      "Item 5084 test rmse, test r2, time taken: 0.48483816837168997, -0.2536962640534144, 32.29159903526306\n",
      "Item 5115 test rmse, test r2, time taken: 1.984032733308039, -0.5916072899849456, 22.72792363166809\n",
      "Item 5166 test rmse, test r2, time taken: 0.9327549578095103, -0.010525837145904715, 16.628384113311768\n",
      "Item 5174 test rmse, test r2, time taken: 1.5610748993744008, 0.0064625087352429, 29.039743423461914\n",
      "Item 5220 test rmse, test r2, time taken: 1.1397262778371942, -0.6012534196538015, 56.96775937080383\n",
      "Item 5221 test rmse, test r2, time taken: 4.6293483024966875, -3.384603004532856, 30.445831298828125\n",
      "Item 5223 test rmse, test r2, time taken: 1.7385732597608472, -0.13060467174211787, 25.343013525009155\n",
      "Item 5240 test rmse, test r2, time taken: 1.6617347539655776, -0.656394885806457, 50.75984573364258\n",
      "Item 5257 test rmse, test r2, time taken: 1.8284862279670955, -0.4659931311624299, 23.61966562271118\n",
      "Item 5352 test rmse, test r2, time taken: 1.8571034654462744, -0.2931063092281625, 37.48501777648926\n",
      "Item 5375 test rmse, test r2, time taken: 0.016435842141111406, 0.0, 45.556222438812256\n",
      "Item 5467 test rmse, test r2, time taken: 1.5545530649607466, -0.06981480616296976, 25.045747756958008\n",
      "Item 5473 test rmse, test r2, time taken: 2.208305124655146, -0.6651844226852321, 39.66291642189026\n",
      "Item 5477 test rmse, test r2, time taken: 2.6170048915725475, -0.11213592551190521, 36.26051211357117\n",
      "Item 5482 test rmse, test r2, time taken: 0.42393399297616874, -0.06742805934972074, 35.115896701812744\n",
      "Item 5528 test rmse, test r2, time taken: 0.6801491192669608, -0.0074461510018444255, 31.0844943523407\n",
      "Item 5546 test rmse, test r2, time taken: 2.583144341146081, -0.27593794994168186, 34.038981199264526\n",
      "Item 5622 test rmse, test r2, time taken: 2.360578476774383, -0.025758934981968684, 105.63360810279846\n",
      "Item 5787 test rmse, test r2, time taken: 5.60871200934908, -0.06802346772008527, 25.518975734710693\n",
      "Item 5845 test rmse, test r2, time taken: 3.193355731593015, -0.3664085335057936, 54.18805241584778\n",
      "Item 5847 test rmse, test r2, time taken: 3.3350682543458356, -0.2133270244522023, 29.81740713119507\n",
      "Item 5880 test rmse, test r2, time taken: 6.416571991847121, -0.2053457267819503, 83.95661973953247\n",
      "Item 5986 test rmse, test r2, time taken: 4.962253211097653, 0.25462616857365294, 45.79126024246216\n",
      "Item 5993 test rmse, test r2, time taken: 1.1023184213622998, -0.0006754487673776843, 20.30025029182434\n",
      "Item 6026 test rmse, test r2, time taken: 3.377004429803356, -0.025916304351876862, 33.9946084022522\n",
      "Item 6035 test rmse, test r2, time taken: 0.9150626511548241, -0.0007230029606406507, 17.727580308914185\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(columns = [\"rmse_train_lstm\", \"r2_train_lstm\", \"rmse_test_lstm\", \"r2_test_lstm\", \"Time Taken\"])\n",
    "prediction_df = pd.DataFrame()\n",
    "prediction_df.index = df_validation.index[optimal_sequence_length:]\n",
    "results = results1\n",
    "\n",
    "for string_i in results.columns: \n",
    "    \n",
    "    i = int(string_i)\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = np.array(df_sales.iloc[:, i]).reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    train_data_normalized = scaler.fit_transform(data)\n",
    "    sequences = load_and_partition_data(train_data_normalized, optimal_sequence_length+1)\n",
    "\n",
    "    train_data = torch.tensor(np.array(sequences[:-28]), dtype=torch.float)\n",
    "    val_data = torch.tensor(np.array(sequences[-28:]), dtype=torch.float)\n",
    "    train_loader = DataLoader(train_data, batch_size=optimal_batch_size , shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=optimal_batch_size, shuffle=False, drop_last=False)\n",
    "    ##############################################################  Training  ##########################################################\n",
    "    #####  Parameters  ######################\n",
    "    num_features = len(df_sales[[i]].columns)\n",
    "    D_MODEL = optimal_d_model  \n",
    "    NUM_HEADS = optimal_num_head \n",
    "    NUM_LAYERS = optimal_num_layer \n",
    "    NUM_EPOCHS = 200\n",
    "    LR = 0.001\n",
    "    \n",
    "    #####Init the Model #######################\n",
    "    model = TransformerWithPE(num_features, num_features, D_MODEL, NUM_HEADS, NUM_LAYERS)\n",
    "    model.to(device)\n",
    "    early_stopper = utils.EarlyStopper(patience=20)\n",
    "    ##### Set Criterion Optimzer and scheduler ####################\n",
    "    criterion = torch.nn.MSELoss().to(device)    # mean-squared error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR,weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  patience=20,factor =0.1,min_lr=1e-7, eps=1e-08)\n",
    "    # Train the model\n",
    "    train_loss_, val_loss_ = [], []\n",
    "    for epoch in range(NUM_EPOCHS): \n",
    "        train_loss, val_loss = 0, 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "            pred = model(src.to(device), tgt.to(device))\n",
    "            loss = criterion(pred, tgt_y.to(device))\n",
    "            train_loss += loss.item()\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss/=len(train_loader.dataset)\n",
    "        train_loss_.append(train_loss)\n",
    "        #Evaluate on test     \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "                val = model(src.to(device), tgt.to(device))\n",
    "                loss = criterion(val, tgt_y.to(device))\n",
    "                val_loss += loss.item()\n",
    "        val_loss/=len(val_loader.dataset)\n",
    "        val_loss_.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "        if early_stopper.early_stop(val_loss, model, 'Models/transformer_final.pth'):\n",
    "            early_stopped = epoch+1\n",
    "            break\n",
    "    ##############################################################  Testing  ##########################################################\n",
    "    model = torch.load('Models/transformer_final.pth')\n",
    "    sequences_tensor = Variable(torch.Tensor(sequences))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src, tgt, tgt_y = split_sequence(sequences_tensor, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "        predicts_ = model(src.to(device), tgt.to(device))\n",
    "    predicts_ = predicts_.cpu().numpy().reshape(-1)\n",
    "    forecasts_ = np.zeros(28)\n",
    "    src = train_data_normalized[-optimal_sequence_length:]\n",
    "    src = Variable(torch.Tensor(src)).unsqueeze(0)\n",
    "    tgt_len = 1\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        forecasted = model.infer(src.to(device), tgt_len)\n",
    "    forecasts_[0] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "    for j in range(1, 28):\n",
    "        src = torch.cat((src[:, 1:].to(device), forecasted), dim = 1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecasted = model.infer(src.to(device), tgt_len)\n",
    "        forecasts_[j] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "    all_prediction = np.append(predicts_, forecasts_)\n",
    "    \n",
    "    sales_validation = pd.DataFrame(df_validation.iloc[:,i])\n",
    "    prediction_df[i] = scaler.inverse_transform(np.array(all_prediction).reshape(-1, 1)).reshape(-1)\n",
    "    rmse_train_lstm = np.sqrt(mean_squared_error(sales_validation[optimal_sequence_length:-28], prediction_df.iloc[:-28][i]))\n",
    "    r2_train_lstm = r2_score(sales_validation[optimal_sequence_length:-28], prediction_df.iloc[:-28][i])\n",
    "    rmse_test_lstm = np.sqrt(mean_squared_error(sales_validation[-28:], prediction_df.iloc[-28:][i]))\n",
    "    r2_test_lstm = r2_score(sales_validation[-28:], prediction_df.iloc[-28:][i])\n",
    "    time_taken = time.time() - start_time\n",
    "\n",
    "    summary_df.loc[i] = [rmse_train_lstm, r2_train_lstm, rmse_test_lstm, r2_test_lstm, time_taken]    \n",
    "    print(f\"Item {i} test rmse, test r2, time taken: {rmse_test_lstm}, {r2_test_lstm}, {time_taken}\")\n",
    "\n",
    "summary_df.to_csv(\"Baseline_transformer_Summary_1.csv\")\n",
    "prediction_df.to_csv(\"Baseline_transformer_Results_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80de886-e5fa-41da-896a-85d3ea0e8c6c",
   "metadata": {},
   "source": [
    "### Batch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f428f4-5ea5-4337-aa12-b41b5e5647cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.read_csv(\"Baseline_LSTM_Results_2.csv\")\n",
    "results2 = results2.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb102780-826d-4e61-85bc-6e06f26d263f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 6100 test rmse, test r2, time taken: 0.39112594947198903, -0.04292116997118356, 21.37938404083252\n",
      "Item 6366 test rmse, test r2, time taken: 1.0015036679257245, -0.08016418124319391, 21.076661586761475\n",
      "Item 6443 test rmse, test r2, time taken: 3.883641709902396, -0.006196015811826605, 59.56764554977417\n",
      "Item 6478 test rmse, test r2, time taken: 0.26509694144981794, -0.05955170151888045, 25.595710277557373\n",
      "Item 6563 test rmse, test r2, time taken: 0.2823227187931304, -1.3144294872832614, 29.11493945121765\n",
      "Item 6576 test rmse, test r2, time taken: 1.848810750523011, -0.5200177730797366, 36.38629388809204\n",
      "Item 6618 test rmse, test r2, time taken: 0.2059998816422971, -0.23221428776022468, 22.513224601745605\n",
      "Item 6627 test rmse, test r2, time taken: 0.7881595595701999, -0.05873318524357196, 20.1295063495636\n",
      "Item 6667 test rmse, test r2, time taken: 1.4904248196390708, -0.3489938467149396, 19.76951003074646\n",
      "Item 6674 test rmse, test r2, time taken: 1.58774881429458, -0.006837441201413164, 26.501376390457153\n",
      "Item 6755 test rmse, test r2, time taken: 4.606953428514078, 0.047203871065155, 48.023932695388794\n",
      "Item 6871 test rmse, test r2, time taken: 1.7418168455932117, 0.00016901046811579334, 29.990714073181152\n",
      "Item 6881 test rmse, test r2, time taken: 1.099839705394871, -0.1344061531213545, 20.884671688079834\n",
      "Item 6910 test rmse, test r2, time taken: 0.04995447411788978, 0.0, 17.01019859313965\n",
      "Item 6986 test rmse, test r2, time taken: 2.1048312355408894, -1.198333285826033, 34.60853838920593\n",
      "Item 6990 test rmse, test r2, time taken: 11.207431370341045, -2.8643609484750296, 54.1217885017395\n",
      "Item 7096 test rmse, test r2, time taken: 2.1089810166287113, -0.14555713795802028, 68.56764578819275\n",
      "Item 7171 test rmse, test r2, time taken: 1.7997289498717237, -0.264638966990538, 23.57634973526001\n",
      "Item 7183 test rmse, test r2, time taken: 2.0288048503583864, -0.1314805437365949, 21.3670871257782\n",
      "Item 7185 test rmse, test r2, time taken: 1.3544665862119611, -0.5719240555203413, 64.09339833259583\n",
      "Item 7200 test rmse, test r2, time taken: 0.260112285928306, -0.020080511769720477, 20.36630344390869\n",
      "Item 7257 test rmse, test r2, time taken: 0.6044347597519995, -0.012111805570397705, 41.378647327423096\n",
      "Item 7261 test rmse, test r2, time taken: 0.45871703741593034, -0.7184407833944586, 22.217278003692627\n",
      "Item 7268 test rmse, test r2, time taken: 1.8083866705394482, -0.017414953390811228, 19.57776975631714\n",
      "Item 7270 test rmse, test r2, time taken: 1.1978401329032895, -0.15730416815958392, 21.97130823135376\n",
      "Item 7318 test rmse, test r2, time taken: 0.12977068609271644, 0.0, 19.758373975753784\n",
      "Item 7333 test rmse, test r2, time taken: 0.9394575455987793, -0.08796084324884612, 19.077459812164307\n",
      "Item 7334 test rmse, test r2, time taken: 1.5438686393180654, -0.1263941014878449, 23.309771299362183\n",
      "Item 7342 test rmse, test r2, time taken: 0.18834240360901428, -0.030026778585967806, 18.73992085456848\n",
      "Item 7441 test rmse, test r2, time taken: 2.051460968464456, -0.045455579982372374, 41.094719648361206\n",
      "Item 7481 test rmse, test r2, time taken: 0.6863285226715435, -0.014562426839237919, 22.95968794822693\n",
      "Item 7551 test rmse, test r2, time taken: 0.789260527556552, -0.06169310739420886, 24.0499267578125\n",
      "Item 7562 test rmse, test r2, time taken: 1.4456525912696037, -0.269163864509143, 24.054847240447998\n",
      "Item 7607 test rmse, test r2, time taken: 1.5670028720804448, -0.04398613496147297, 89.87990164756775\n",
      "Item 7671 test rmse, test r2, time taken: 0.5542322934316508, -0.06089855993253712, 74.8056116104126\n",
      "Item 7742 test rmse, test r2, time taken: 1.3270880833961916, -0.04365201842499378, 23.406330347061157\n",
      "Item 7761 test rmse, test r2, time taken: 0.6613888603793328, -11.70182281899837, 37.07973647117615\n",
      "Item 7839 test rmse, test r2, time taken: 1.7968325054696959, -0.622582005978592, 20.986899614334106\n",
      "Item 7855 test rmse, test r2, time taken: 1.0036578306101591, -0.2263136150635887, 22.075026035308838\n",
      "Item 7874 test rmse, test r2, time taken: 1.9128669511137038, -0.09325572353956568, 20.824944734573364\n",
      "Item 7884 test rmse, test r2, time taken: 1.377698120322602, -0.06595476706339376, 17.87545609474182\n",
      "Item 7885 test rmse, test r2, time taken: 1.58613516990119, -2.1407748810872964, 49.67113924026489\n",
      "Item 7888 test rmse, test r2, time taken: 1.987954659609753, -0.08371443276414015, 52.25215554237366\n",
      "Item 7890 test rmse, test r2, time taken: 2.3010742215294124, -0.04512461662184264, 32.60143184661865\n",
      "Item 7971 test rmse, test r2, time taken: 0.46875442561043695, -0.007420338239921831, 47.15458917617798\n",
      "Item 8048 test rmse, test r2, time taken: 1.2789003662590532, -0.09785919443917157, 44.704123973846436\n",
      "Item 8152 test rmse, test r2, time taken: 0.6715887936755168, 0.0039191489921688305, 31.12533664703369\n",
      "Item 8164 test rmse, test r2, time taken: 4.265428754225984, -0.9585340994898006, 24.128614902496338\n",
      "Item 8166 test rmse, test r2, time taken: 1.4809674313449603, 0.023000344522545402, 65.8573899269104\n",
      "Item 8174 test rmse, test r2, time taken: 0.7931968442889146, -0.05397950275913632, 22.573528051376343\n",
      "Item 8232 test rmse, test r2, time taken: 0.7701332098399676, -0.5146398897210249, 38.94412136077881\n",
      "Item 8249 test rmse, test r2, time taken: 4.446140855348298, -0.4453272506190695, 31.928374767303467\n",
      "Item 8308 test rmse, test r2, time taken: 2.1979361315635635, -0.29929462055957456, 65.80299878120422\n",
      "Item 8313 test rmse, test r2, time taken: 0.6476157755883388, -0.09971389681623521, 18.846460819244385\n",
      "Item 8494 test rmse, test r2, time taken: 1.901039253474828, -0.16502343367996342, 45.51285219192505\n",
      "Item 8512 test rmse, test r2, time taken: 1.7435973181330289, 0.19775726000816507, 127.87152624130249\n",
      "Item 8530 test rmse, test r2, time taken: 2.253359015105679, -0.0012221959635565494, 16.68441390991211\n",
      "Item 8561 test rmse, test r2, time taken: 1.0851251335051024, -0.0001704218913778366, 35.28182601928711\n",
      "Item 8564 test rmse, test r2, time taken: 1.3669550121889618, -0.008922691593142629, 19.57836413383484\n",
      "Item 8606 test rmse, test r2, time taken: 0.8442533023955314, -0.18391248446380537, 28.638006925582886\n",
      "Item 8610 test rmse, test r2, time taken: 7.047267450346031, 0.25675150023673776, 51.45530581474304\n",
      "Item 8621 test rmse, test r2, time taken: 5.688148550796696, -0.08961969956054805, 35.66433835029602\n",
      "Item 8655 test rmse, test r2, time taken: 2.6332700737469255, -1.7736445125164555, 58.322710037231445\n",
      "Item 8670 test rmse, test r2, time taken: 6.903813049217936, -0.8891559929699013, 17.01617169380188\n",
      "Item 8699 test rmse, test r2, time taken: 5.347003028534234, -1.4398504460138177, 25.17963171005249\n",
      "Item 8725 test rmse, test r2, time taken: 6.811713280633652, -0.18650834172568298, 31.78143000602722\n",
      "Item 8788 test rmse, test r2, time taken: 0.003527172655159823, 0.0, 33.06164336204529\n",
      "Item 8814 test rmse, test r2, time taken: 1.5255478371973634, -0.21965255588556243, 34.70419478416443\n",
      "Item 8829 test rmse, test r2, time taken: 0.5974462500482928, 0.011157084769379821, 41.71396088600159\n",
      "Item 8844 test rmse, test r2, time taken: 2.8021316044538453, -0.004064941850334236, 25.05824565887451\n",
      "Item 8934 test rmse, test r2, time taken: 1.17959377854519, -0.007285431383097674, 17.16003656387329\n",
      "Item 8978 test rmse, test r2, time taken: 1.140762800205108, -1.482361014121972, 25.026305437088013\n",
      "Item 8999 test rmse, test r2, time taken: 0.6947179558863672, -0.04238099717093924, 17.493170022964478\n",
      "Item 9011 test rmse, test r2, time taken: 2.974313325415999, -2.502872308118074, 61.4855055809021\n",
      "Item 9024 test rmse, test r2, time taken: 2.0371287079474625, -0.4402463055471708, 22.683470249176025\n",
      "Item 9035 test rmse, test r2, time taken: 7.93992180354472, -0.05835565021801692, 45.27716541290283\n",
      "Item 9048 test rmse, test r2, time taken: 2.3377628115521634, -0.7029673334864075, 25.631925106048584\n",
      "Item 9060 test rmse, test r2, time taken: 9.703397143928482, -7.485830353846964, 18.65167999267578\n",
      "Item 9078 test rmse, test r2, time taken: 0.8688000670089177, -0.1314987155732401, 18.361271381378174\n",
      "Item 9081 test rmse, test r2, time taken: 0.9925799905778215, -0.2163914796114128, 52.351118326187134\n",
      "Item 9088 test rmse, test r2, time taken: 2.516774218492071, -0.013671266385637315, 45.49105405807495\n",
      "Item 9131 test rmse, test r2, time taken: 3.103600691614365, -0.04190844458381693, 28.43669819831848\n",
      "Item 9134 test rmse, test r2, time taken: 6.379743523642784, -0.084920573341841, 50.70472717285156\n",
      "Item 9200 test rmse, test r2, time taken: 0.5463927442435701, -0.03109825671464006, 32.3294415473938\n",
      "Item 9303 test rmse, test r2, time taken: 2.364625394468951, -0.1475652756113286, 77.66997933387756\n",
      "Item 9416 test rmse, test r2, time taken: 2.601051741590705, -2.424723731486722e-05, 19.467182159423828\n",
      "Item 9434 test rmse, test r2, time taken: 0.6447066873088659, -0.06145610008483704, 18.46228313446045\n",
      "Item 9479 test rmse, test r2, time taken: 3.5577501354277197, -0.02146654086367361, 26.406169891357422\n",
      "Item 9549 test rmse, test r2, time taken: 0.6402550812620201, -0.057179046579471926, 18.331257343292236\n",
      "Item 9560 test rmse, test r2, time taken: 0.3712879334790289, -0.0007232218976678251, 17.804238080978394\n",
      "Item 9581 test rmse, test r2, time taken: 0.9764897140882142, -0.03829057609520081, 37.202990770339966\n",
      "Item 9666 test rmse, test r2, time taken: 0.26043813944731087, -0.02263790752617556, 27.39314293861389\n",
      "Item 9749 test rmse, test r2, time taken: 0.6033784780898676, -0.13716103925292078, 30.17266273498535\n",
      "Item 9779 test rmse, test r2, time taken: 0.5504804422527414, -0.006671671039723215, 29.302711725234985\n",
      "Item 9788 test rmse, test r2, time taken: 1.4200198265516901, -0.24284728405276357, 42.65164303779602\n",
      "Item 9836 test rmse, test r2, time taken: 0.950945933879286, -0.018634719285421042, 22.565503358840942\n",
      "Item 9843 test rmse, test r2, time taken: 1.286806212821641, -0.2640723075125586, 22.81297755241394\n",
      "Item 9946 test rmse, test r2, time taken: 0.8397023748113521, -0.14451027196446864, 59.253742933273315\n",
      "Item 9991 test rmse, test r2, time taken: 0.5862738218756213, 0.00928631078730957, 54.5667085647583\n",
      "Item 10013 test rmse, test r2, time taken: 0.44638011471716094, -0.0626944363461639, 48.032108545303345\n",
      "Item 10115 test rmse, test r2, time taken: 1.2457244919388093, -0.17549211178348245, 19.5651695728302\n",
      "Item 10163 test rmse, test r2, time taken: 0.917591003748894, -0.5002432457412453, 25.105706214904785\n",
      "Item 10253 test rmse, test r2, time taken: 0.26144989038058264, -0.030598835021820037, 23.383294820785522\n",
      "Item 10276 test rmse, test r2, time taken: 0.40480360778485935, -0.33823868048437866, 29.543291091918945\n",
      "Item 10307 test rmse, test r2, time taken: 0.46932984669298133, -0.3082733024055768, 51.13904690742493\n",
      "Item 10357 test rmse, test r2, time taken: 0.531651606520498, -0.025927267042629154, 47.39224410057068\n",
      "Item 10376 test rmse, test r2, time taken: 0.03849612425864398, 0.0, 29.6242036819458\n",
      "Item 10378 test rmse, test r2, time taken: 0.8117399964276971, -0.01892447394781671, 18.694528579711914\n",
      "Item 10416 test rmse, test r2, time taken: 0.7370032573531103, -0.0236737025425251, 24.12714195251465\n",
      "Item 10421 test rmse, test r2, time taken: 0.5318602636447678, -0.18595864489153469, 36.74173069000244\n",
      "Item 10522 test rmse, test r2, time taken: 0.30321836355585213, 0.03890614957291605, 40.803300857543945\n",
      "Item 10621 test rmse, test r2, time taken: 0.5061517996495225, -0.2553292570134069, 31.38429284095764\n",
      "Item 10671 test rmse, test r2, time taken: 0.4226264864446778, -0.06895196399195092, 21.329878330230713\n",
      "Item 10676 test rmse, test r2, time taken: 0.9732892272976569, -0.04308548491482789, 48.61155986785889\n",
      "Item 10720 test rmse, test r2, time taken: 0.6477514715269627, -0.12654884791243481, 72.1332380771637\n",
      "Item 10810 test rmse, test r2, time taken: 1.054460889702968, -0.07487054259424042, 22.18624258041382\n",
      "Item 10862 test rmse, test r2, time taken: 2.495891450455072, -0.28795034806025943, 32.72671866416931\n",
      "Item 10920 test rmse, test r2, time taken: 0.7054965504977658, -0.016189323143670276, 36.23911738395691\n",
      "Item 11001 test rmse, test r2, time taken: 0.8306746998980034, -0.06701388230315586, 19.95552706718445\n",
      "Item 11035 test rmse, test r2, time taken: 1.533484609044939, -0.23237622740863895, 57.65059781074524\n",
      "Item 11077 test rmse, test r2, time taken: 0.8785144412965415, -0.17263855983758614, 36.60428190231323\n",
      "Item 11106 test rmse, test r2, time taken: 1.1860475245611728, 0.0010329305019335377, 46.655911922454834\n",
      "Item 11112 test rmse, test r2, time taken: 1.5922990972194513, 0.00011747013852636545, 30.456945180892944\n",
      "Item 11157 test rmse, test r2, time taken: 0.758219112360006, -0.11564019386343638, 31.63597321510315\n",
      "Item 11182 test rmse, test r2, time taken: 0.44254014369371714, -0.1631814739687676, 19.744330883026123\n",
      "Item 11213 test rmse, test r2, time taken: 1.4222823423577169, -0.3731112174233089, 49.53964638710022\n",
      "Item 11264 test rmse, test r2, time taken: 1.060010388799803, -0.01605497935523803, 50.11177325248718\n",
      "Item 11272 test rmse, test r2, time taken: 1.630236395294021, -0.09261344119577108, 20.250561714172363\n",
      "Item 11318 test rmse, test r2, time taken: 0.4251517297844254, -0.07356917255706219, 18.515247583389282\n",
      "Item 11319 test rmse, test r2, time taken: 2.5404637599540125, -1.3512553878538598, 25.070931673049927\n",
      "Item 11321 test rmse, test r2, time taken: 0.6985322812947533, -0.21444673282701032, 52.597517013549805\n",
      "Item 11338 test rmse, test r2, time taken: 0.8014607104652685, -0.38349996705736933, 25.070380926132202\n",
      "Item 11355 test rmse, test r2, time taken: 0.9815181765450698, -0.00038185141254731825, 49.53972887992859\n",
      "Item 11450 test rmse, test r2, time taken: 0.8117223587692028, -0.10615044791661088, 23.808214902877808\n",
      "Item 11473 test rmse, test r2, time taken: 0.9930651227393343, -0.14542787702668258, 60.973612785339355\n",
      "Item 11565 test rmse, test r2, time taken: 1.3654542685330582, -0.1322547186776426, 43.64616870880127\n",
      "Item 11571 test rmse, test r2, time taken: 1.641434732799612, -0.21468513968952974, 20.84970498085022\n",
      "Item 11575 test rmse, test r2, time taken: 1.3455567843284577, -0.00031718035534455957, 25.62479043006897\n",
      "Item 11580 test rmse, test r2, time taken: 0.6092950477269361, 0.055024295893823405, 64.4321391582489\n",
      "Item 11626 test rmse, test r2, time taken: 0.7256998539483573, -0.13430213727528306, 39.576245069503784\n",
      "Item 11644 test rmse, test r2, time taken: 2.4268561432464053, -0.0014032748145842433, 70.53079032897949\n",
      "Item 11720 test rmse, test r2, time taken: 1.3847451504045736, -0.004903074298184373, 48.90330481529236\n",
      "Item 11885 test rmse, test r2, time taken: 1.4381136477997027, -0.0926185696539148, 38.05714511871338\n",
      "Item 11943 test rmse, test r2, time taken: 2.263894628264939, -0.49318900338286364, 20.55494999885559\n",
      "Item 11945 test rmse, test r2, time taken: 1.7273852804707686, -0.28535503694212516, 21.997416019439697\n",
      "Item 11978 test rmse, test r2, time taken: 2.901231480038026, -0.058386684041489945, 19.30984592437744\n",
      "Item 12084 test rmse, test r2, time taken: 5.035851496840639, -0.3423862962537283, 35.852965354919434\n",
      "Item 12091 test rmse, test r2, time taken: 3.281886507722403, -0.0184888161697212, 27.512787342071533\n",
      "Item 12124 test rmse, test r2, time taken: 3.5014631093125015, -0.07469043182100554, 56.79934597015381\n",
      "Item 12133 test rmse, test r2, time taken: 0.7817415883772939, -0.15172598611284815, 16.75556492805481\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(columns = [\"rmse_train_lstm\", \"r2_train_lstm\", \"rmse_test_lstm\", \"r2_test_lstm\", \"Time Taken\"])\n",
    "prediction_df = pd.DataFrame()\n",
    "prediction_df.index = df_validation.index[optimal_sequence_length:]\n",
    "results = results2\n",
    "\n",
    "for string_i in results.columns: \n",
    "    \n",
    "    i = int(string_i)\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = np.array(df_sales.iloc[:, i]).reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    train_data_normalized = scaler.fit_transform(data)\n",
    "    sequences = load_and_partition_data(train_data_normalized, optimal_sequence_length+1)\n",
    "\n",
    "    train_data = torch.tensor(np.array(sequences[:-28]), dtype=torch.float)\n",
    "    val_data = torch.tensor(np.array(sequences[-28:]), dtype=torch.float)\n",
    "    train_loader = DataLoader(train_data, batch_size=optimal_batch_size , shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=optimal_batch_size, shuffle=False, drop_last=False)\n",
    "    ##############################################################  Training  ##########################################################\n",
    "    #####  Parameters  ######################\n",
    "    num_features = len(df_sales[[i]].columns)\n",
    "    D_MODEL = optimal_d_model  \n",
    "    NUM_HEADS = optimal_num_head \n",
    "    NUM_LAYERS = optimal_num_layer \n",
    "    NUM_EPOCHS = 200\n",
    "    LR = 0.001\n",
    "    \n",
    "    #####Init the Model #######################\n",
    "    model = TransformerWithPE(num_features, num_features, D_MODEL, NUM_HEADS, NUM_LAYERS)\n",
    "    model.to(device)\n",
    "    early_stopper = utils.EarlyStopper(patience=20)\n",
    "    ##### Set Criterion Optimzer and scheduler ####################\n",
    "    criterion = torch.nn.MSELoss().to(device)    # mean-squared error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR,weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  patience=20,factor =0.1,min_lr=1e-7, eps=1e-08)\n",
    "    # Train the model\n",
    "    train_loss_, val_loss_ = [], []\n",
    "    for epoch in range(NUM_EPOCHS): \n",
    "        train_loss, val_loss = 0, 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "            pred = model(src.to(device), tgt.to(device))\n",
    "            loss = criterion(pred, tgt_y.to(device))\n",
    "            train_loss += loss.item()\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss/=len(train_loader.dataset)\n",
    "        train_loss_.append(train_loss)\n",
    "        #Evaluate on test     \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "                val = model(src.to(device), tgt.to(device))\n",
    "                loss = criterion(val, tgt_y.to(device))\n",
    "                val_loss += loss.item()\n",
    "        val_loss/=len(val_loader.dataset)\n",
    "        val_loss_.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "        if early_stopper.early_stop(val_loss, model, 'Models/transformer_final.pth'):\n",
    "            early_stopped = epoch+1\n",
    "            break\n",
    "    ##############################################################  Testing  ##########################################################\n",
    "    model = torch.load('Models/transformer_final.pth')\n",
    "    sequences_tensor = Variable(torch.Tensor(sequences))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src, tgt, tgt_y = split_sequence(sequences_tensor, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "        predicts_ = model(src.to(device), tgt.to(device))\n",
    "    predicts_ = predicts_.cpu().numpy().reshape(-1)\n",
    "    forecasts_ = np.zeros(28)\n",
    "    src = train_data_normalized[-optimal_sequence_length:]\n",
    "    src = Variable(torch.Tensor(src)).unsqueeze(0)\n",
    "    tgt_len = 1\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        forecasted = model.infer(src.to(device), tgt_len)\n",
    "    forecasts_[0] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "    for j in range(1, 28):\n",
    "        src = torch.cat((src[:, 1:].to(device), forecasted), dim = 1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecasted = model.infer(src.to(device), tgt_len)\n",
    "        forecasts_[j] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "    all_prediction = np.append(predicts_, forecasts_)\n",
    "    \n",
    "    sales_validation = pd.DataFrame(df_validation.iloc[:,i])\n",
    "    prediction_df[i] = scaler.inverse_transform(np.array(all_prediction).reshape(-1, 1)).reshape(-1)\n",
    "    rmse_train_lstm = np.sqrt(mean_squared_error(sales_validation[optimal_sequence_length:-28], prediction_df.iloc[:-28][i]))\n",
    "    r2_train_lstm = r2_score(sales_validation[optimal_sequence_length:-28], prediction_df.iloc[:-28][i])\n",
    "    rmse_test_lstm = np.sqrt(mean_squared_error(sales_validation[-28:], prediction_df.iloc[-28:][i]))\n",
    "    r2_test_lstm = r2_score(sales_validation[-28:], prediction_df.iloc[-28:][i])\n",
    "    time_taken = time.time() - start_time\n",
    "\n",
    "    summary_df.loc[i] = [rmse_train_lstm, r2_train_lstm, rmse_test_lstm, r2_test_lstm, time_taken]    \n",
    "    print(f\"Item {i} test rmse, test r2, time taken: {rmse_test_lstm}, {r2_test_lstm}, {time_taken}\")\n",
    "\n",
    "summary_df.to_csv(\"Baseline_transformer_Summary_2.csv\")\n",
    "prediction_df.to_csv(\"Baseline_transformer_Results_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9d0b6-21a2-44b9-ab07-528c21c782d5",
   "metadata": {},
   "source": [
    "### Batch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "518c344a-7992-452b-be9e-98d4c94c40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = pd.read_csv(\"Baseline_LSTM_Results_3.csv\")\n",
    "results3 = results3.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfbd9e-4546-4f83-b48b-b7a0eaf8c007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 12269 test rmse, test r2, time taken: 1.6386697505892927, -0.12458708566942156, 60.79895782470703\n",
      "Item 12274 test rmse, test r2, time taken: 0.6243483210266192, -0.018705625198354836, 20.08068537712097\n",
      "Item 12308 test rmse, test r2, time taken: 0.07561212066809937, 0.0, 46.395798206329346\n",
      "Item 12314 test rmse, test r2, time taken: 0.4746681618744622, -0.032999609915017825, 23.04255223274231\n",
      "Item 12342 test rmse, test r2, time taken: 0.8238117294540982, -0.007715833749135204, 80.37517642974854\n",
      "Item 12363 test rmse, test r2, time taken: 0.4560931139296918, -0.07295005264526955, 32.14507484436035\n",
      "Item 12466 test rmse, test r2, time taken: 3.080471745941351, -0.04842390687622267, 24.556649684906006\n",
      "Item 12490 test rmse, test r2, time taken: 0.1855780630413639, -1.2833556762625875e-05, 41.29540014266968\n",
      "Item 12493 test rmse, test r2, time taken: 0.6229631484940233, -0.11859241968810297, 25.661415576934814\n",
      "Item 12552 test rmse, test r2, time taken: 0.001954040486990559, 0.0, 21.223590850830078\n",
      "Item 12599 test rmse, test r2, time taken: 1.0062006513267734, -0.061166797557020924, 49.95089650154114\n",
      "Item 12618 test rmse, test r2, time taken: 0.5424828805554194, -0.016394439407194206, 18.286914825439453\n",
      "Item 12672 test rmse, test r2, time taken: 0.19862589778081488, -0.14557636515111172, 19.216339588165283\n",
      "Item 12675 test rmse, test r2, time taken: 0.3558902409709971, -0.0343725528835539, 24.613674640655518\n",
      "Item 12684 test rmse, test r2, time taken: 0.5756250499340434, -0.06464693163717539, 17.88741445541382\n",
      "Item 12693 test rmse, test r2, time taken: 0.5953756012275057, -0.052674740625070715, 35.856340408325195\n",
      "Item 12694 test rmse, test r2, time taken: 0.0001368886071193021, 0.0, 34.73501539230347\n",
      "Item 12696 test rmse, test r2, time taken: 1.0312781893760479, -0.04750151739204522, 24.29032564163208\n",
      "Item 12756 test rmse, test r2, time taken: 1.2778413496166716, -0.11903562552052716, 84.2755217552185\n",
      "Item 12796 test rmse, test r2, time taken: 0.5096193220338807, -0.0030250889555341054, 22.708333015441895\n",
      "Item 12806 test rmse, test r2, time taken: 1.3094724727887452, -0.02778213691231901, 26.322848320007324\n",
      "Item 12842 test rmse, test r2, time taken: 0.32696887111718803, -0.11755167814459044, 76.46536588668823\n",
      "Item 12860 test rmse, test r2, time taken: 0.6817452572304766, -0.0038150167297490434, 55.27124071121216\n",
      "Item 12924 test rmse, test r2, time taken: 0.9565011536599738, -0.038027864328571415, 18.156033277511597\n",
      "Item 12932 test rmse, test r2, time taken: 0.4330588415810418, -0.0002131214480738386, 17.89552879333496\n",
      "Item 12940 test rmse, test r2, time taken: 0.8809291013587104, -0.9753645713980561, 42.9944851398468\n",
      "Item 12988 test rmse, test r2, time taken: 1.0412796455764277, 0.0022741462103887944, 48.15872836112976\n",
      "Item 13004 test rmse, test r2, time taken: 0.8259423860861265, -0.441589668206946, 19.987658977508545\n",
      "Item 13009 test rmse, test r2, time taken: 4.007966444998872, -0.008489373718908455, 51.573765993118286\n",
      "Item 13013 test rmse, test r2, time taken: 0.25773308175353904, -0.001504840024199039, 17.477211952209473\n",
      "Item 13130 test rmse, test r2, time taken: 0.5142652404824909, -0.02139650371288271, 42.11325764656067\n",
      "Item 13200 test rmse, test r2, time taken: 1.2197206092569093, -0.12692869360628056, 106.27603101730347\n",
      "Item 13328 test rmse, test r2, time taken: 0.524892035615624, -5.244709849083762e-06, 89.38631224632263\n",
      "Item 13423 test rmse, test r2, time taken: 0.3260830768106284, -0.11150474157483181, 45.43151783943176\n",
      "Item 13436 test rmse, test r2, time taken: 0.3896218847838419, -0.03491553975974382, 19.124557971954346\n",
      "Item 13634 test rmse, test r2, time taken: 0.7237304016675795, -0.03961515020143347, 43.88548040390015\n",
      "Item 13645 test rmse, test r2, time taken: 0.7784968001454583, -0.015275423042706349, 22.93692421913147\n",
      "Item 13686 test rmse, test r2, time taken: 1.5465748058935869, -0.032623681771053015, 31.787229537963867\n",
      "Item 13753 test rmse, test r2, time taken: 0.3800495488310329, -0.1795742197944854, 30.695676565170288\n",
      "Item 13763 test rmse, test r2, time taken: 0.8271536922548304, -0.008270024058019132, 21.836156845092773\n",
      "Item 13786 test rmse, test r2, time taken: 1.151346442081579, -0.0648251287705186, 52.428781509399414\n",
      "Item 13836 test rmse, test r2, time taken: 0.6183219037919158, -0.002476353644633722, 20.555025100708008\n",
      "Item 13888 test rmse, test r2, time taken: 0.588381107286739, -0.028086305647665677, 51.27733612060547\n",
      "Item 13910 test rmse, test r2, time taken: 1.2578391900671306, -0.03713460836612725, 29.025320529937744\n",
      "Item 13951 test rmse, test r2, time taken: 0.49407974345753336, 0.0031979290118302472, 51.60341024398804\n",
      "Item 13956 test rmse, test r2, time taken: 0.5424761299295546, -0.016369143656317364, 31.68591618537903\n",
      "Item 13957 test rmse, test r2, time taken: 1.4451311306545296, -0.6307855817458976, 43.74816584587097\n",
      "Item 14044 test rmse, test r2, time taken: 3.4345512996884127, -0.6044718636485131, 42.12596297264099\n",
      "Item 14051 test rmse, test r2, time taken: 0.6638865325592348, -0.1218971988344244, 42.980793714523315\n",
      "Item 14064 test rmse, test r2, time taken: 1.0504628762057824, -0.126461259584161, 26.07485866546631\n",
      "Item 14116 test rmse, test r2, time taken: 0.835642109721037, -0.06097950516007011, 20.118502378463745\n",
      "Item 14170 test rmse, test r2, time taken: 0.31697050327161164, -0.050249535417318025, 41.637359857559204\n",
      "Item 14221 test rmse, test r2, time taken: 2.112607145090415, -0.04046310329998981, 29.312230110168457\n",
      "Item 14346 test rmse, test r2, time taken: 1.0708868099602695, -0.1955984984595156, 27.102582454681396\n",
      "Item 14382 test rmse, test r2, time taken: 5.373990728728554, -0.024884331899737155, 17.631787538528442\n",
      "Item 14387 test rmse, test r2, time taken: 1.018182465796654, -0.4209253468288663, 27.30825638771057\n",
      "Item 14389 test rmse, test r2, time taken: 0.7806060727566336, -0.012133769505159542, 35.48755407333374\n",
      "Item 14452 test rmse, test r2, time taken: 1.773383958609882, -0.10268080549615699, 41.491957902908325\n",
      "Item 14472 test rmse, test r2, time taken: 1.0173353517544603, -0.325845481791875, 22.702224254608154\n",
      "Item 14477 test rmse, test r2, time taken: 0.41033361292043924, -3.757826966066524e-05, 28.568373680114746\n",
      "Item 14487 test rmse, test r2, time taken: 1.0036151690941548, -0.1821539395008045, 21.373533487319946\n",
      "Item 14562 test rmse, test r2, time taken: 0.6176697439367506, -0.05692040798132325, 19.468348741531372\n",
      "Item 14568 test rmse, test r2, time taken: 1.5308572362399158, -0.11827311025838183, 32.06264805793762\n",
      "Item 14600 test rmse, test r2, time taken: 0.700061196305437, -0.3158464794551994, 27.055376291275024\n",
      "Item 14604 test rmse, test r2, time taken: 0.8444081193623569, 0.007084091503842149, 59.32003712654114\n",
      "Item 14688 test rmse, test r2, time taken: 0.7002575261368065, -0.036233726906771846, 19.3150532245636\n",
      "Item 14697 test rmse, test r2, time taken: 1.3787132974092131, -0.4398711878832271, 17.088444471359253\n",
      "Item 14856 test rmse, test r2, time taken: 1.841501326980634, -0.14055927740060303, 38.02057409286499\n",
      "Item 14894 test rmse, test r2, time taken: 7.990231654131732, -1.1788934650515395, 38.20209860801697\n",
      "Item 14916 test rmse, test r2, time taken: 0.962896528873234, -0.3898681924432885, 22.789390325546265\n",
      "Item 14938 test rmse, test r2, time taken: 0.6284932395582377, -0.4337173226925932, 49.49365735054016\n",
      "Item 14940 test rmse, test r2, time taken: 0.9352728643533672, -0.4198602470887567, 27.071268796920776\n",
      "Item 14969 test rmse, test r2, time taken: 0.32741965722552474, -0.12063529918854954, 48.98460531234741\n",
      "Item 15033 test rmse, test r2, time taken: 0.25796192300297677, -0.003284102230859176, 17.354249000549316\n",
      "Item 15053 test rmse, test r2, time taken: 0.44979302591198467, -0.043513109662516536, 24.686504125595093\n",
      "Item 15074 test rmse, test r2, time taken: 6.4202199242340265, 0.026630375951302687, 57.606374979019165\n",
      "Item 15116 test rmse, test r2, time taken: 0.3238776183879314, -0.09652029289371455, 42.99569511413574\n",
      "Item 15231 test rmse, test r2, time taken: 0.7249927275254229, -0.04324489289206457, 25.073991775512695\n",
      "Item 15248 test rmse, test r2, time taken: 2.1003301255566194, -0.004218096073001387, 20.238067865371704\n",
      "Item 15255 test rmse, test r2, time taken: 0.35989390006976346, -0.057776224343969895, 19.46016836166382\n",
      "Item 15298 test rmse, test r2, time taken: 0.03596698678158102, 0.0, 26.2163405418396\n",
      "Item 15301 test rmse, test r2, time taken: 1.2161657952786158, -0.4790592416056678, 37.77491998672485\n",
      "Item 15383 test rmse, test r2, time taken: 0.8092788448838232, -0.4145093196715486, 45.869921922683716\n",
      "Item 15439 test rmse, test r2, time taken: 1.5005952351833087, -0.003068335753523721, 17.797918796539307\n",
      "Item 15441 test rmse, test r2, time taken: 0.6342730187681868, -0.001285630706190144, 20.17775797843933\n",
      "Item 15477 test rmse, test r2, time taken: 1.4268828645319127, -0.10848600828494481, 22.949604988098145\n",
      "Item 15620 test rmse, test r2, time taken: 0.7976277325951947, 0.0024227203058359015, 16.580437898635864\n",
      "Item 15668 test rmse, test r2, time taken: 0.651601550418404, -0.014860704628084198, 59.991687536239624\n",
      "Item 15707 test rmse, test r2, time taken: 0.5115829326496606, -0.09141597888875985, 18.689765453338623\n",
      "Item 15810 test rmse, test r2, time taken: 0.3510627867950357, -0.006501488890422902, 22.467936515808105\n",
      "Item 15853 test rmse, test r2, time taken: 0.8512313292375545, -0.2596059962004844, 24.002113580703735\n",
      "Item 15868 test rmse, test r2, time taken: 1.166179865738382, -0.03818965504850502, 17.613865852355957\n",
      "Item 15971 test rmse, test r2, time taken: 0.9635101162148211, -0.005286971455615852, 26.676040649414062\n",
      "Item 16001 test rmse, test r2, time taken: 1.521442736052115, -0.143537360606947, 43.107805252075195\n",
      "Item 16029 test rmse, test r2, time taken: 0.6338120056893112, -0.02588483487892934, 31.56374478340149\n",
      "Item 16045 test rmse, test r2, time taken: 0.8145995121057883, -0.02611584665961142, 18.246663570404053\n",
      "Item 16135 test rmse, test r2, time taken: 0.7274379762014216, -0.009406693986607317, 19.049177885055542\n",
      "Item 16140 test rmse, test r2, time taken: 0.316699518695379, -0.5121940529084161, 21.66404104232788\n",
      "Item 16191 test rmse, test r2, time taken: 4.603459800729707, -2.178573605386755, 18.57856249809265\n",
      "Item 16249 test rmse, test r2, time taken: 1.6047400622916301, -0.14517837965888614, 48.45219898223877\n",
      "Item 16307 test rmse, test r2, time taken: 1.1131878081538527, -0.02915538499824666, 49.234755992889404\n",
      "Item 16314 test rmse, test r2, time taken: 3.881373068476858, -0.058049324286554516, 66.07429075241089\n",
      "Item 16514 test rmse, test r2, time taken: 0.43543391349066596, -0.011214362761582608, 23.935023307800293\n",
      "Item 16557 test rmse, test r2, time taken: 1.5842767942476685, -0.12060788226689567, 18.38185214996338\n",
      "Item 16579 test rmse, test r2, time taken: 1.147482736816466, -0.00029635555501617006, 22.58969020843506\n",
      "Item 16624 test rmse, test r2, time taken: 0.8687441568068502, -0.008002837187494727, 20.99274730682373\n",
      "Item 16626 test rmse, test r2, time taken: 0.6693829703830504, -0.009453080041514683, 26.829450368881226\n",
      "Item 16652 test rmse, test r2, time taken: 1.1669042778327392, -0.05907323948560306, 63.09487199783325\n",
      "Item 16661 test rmse, test r2, time taken: 0.4142329523537162, -0.019134303268864006, 17.604201316833496\n",
      "Item 16686 test rmse, test r2, time taken: 1.1498371217796166, -0.10742128076066981, 45.70854735374451\n",
      "Item 16695 test rmse, test r2, time taken: 0.36740696535752276, -0.102401005244662, 22.990397214889526\n",
      "Item 16726 test rmse, test r2, time taken: 0.8589585571375224, 0.0009622012819636705, 21.392927169799805\n",
      "Item 16751 test rmse, test r2, time taken: 1.1444092442486835, -0.11244122899710152, 19.41757583618164\n",
      "Item 16801 test rmse, test r2, time taken: 0.6128294396109759, -0.13683003432532748, 34.38699007034302\n",
      "Item 16831 test rmse, test r2, time taken: 0.7406519171386822, -0.0264323763512766, 23.684224605560303\n",
      "Item 16865 test rmse, test r2, time taken: 0.48723732664736863, 0.08314400697968427, 82.37555932998657\n",
      "Item 16885 test rmse, test r2, time taken: 0.9761825271606295, -0.18964799975419, 26.32659363746643\n",
      "Item 16925 test rmse, test r2, time taken: 0.560380869176388, -0.009003882518381356, 20.473540782928467\n",
      "Item 16960 test rmse, test r2, time taken: 1.4497813080782338, -0.0812748159726897, 33.42830562591553\n",
      "Item 16967 test rmse, test r2, time taken: 2.378508837304123, -0.19357550125966294, 34.12582564353943\n",
      "Item 17010 test rmse, test r2, time taken: 0.6340445704465287, -0.03676912359597018, 23.110217809677124\n",
      "Item 17070 test rmse, test r2, time taken: 2.048002462390803, -0.25317920860963894, 19.456258058547974\n",
      "Item 17222 test rmse, test r2, time taken: 1.0665245696209162, -0.120326798445205, 43.949981927871704\n",
      "Item 17239 test rmse, test r2, time taken: 0.6568157544279974, -0.03116779648664192, 44.83294200897217\n",
      "Item 17247 test rmse, test r2, time taken: 0.2699603689582334, -0.09878505833698759, 21.122424602508545\n",
      "Item 17330 test rmse, test r2, time taken: 1.0006108994053993, -0.04382737081777033, 49.61205506324768\n",
      "Item 17335 test rmse, test r2, time taken: 0.7322748771996996, -0.022874872724629736, 31.735982656478882\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(columns = [\"rmse_train_lstm\", \"r2_train_lstm\", \"rmse_test_lstm\", \"r2_test_lstm\", \"Time Taken\"])\n",
    "prediction_df = pd.DataFrame()\n",
    "prediction_df.index = df_validation.index[optimal_sequence_length:]\n",
    "results = results3\n",
    "\n",
    "for string_i in results.columns: \n",
    "    \n",
    "    i = int(string_i)\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = np.array(df_sales.iloc[:, i]).reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    train_data_normalized = scaler.fit_transform(data)\n",
    "    sequences = load_and_partition_data(train_data_normalized, optimal_sequence_length+1)\n",
    "\n",
    "    train_data = torch.tensor(np.array(sequences[:-28]), dtype=torch.float)\n",
    "    val_data = torch.tensor(np.array(sequences[-28:]), dtype=torch.float)\n",
    "    train_loader = DataLoader(train_data, batch_size=optimal_batch_size , shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=optimal_batch_size, shuffle=False, drop_last=False)\n",
    "    ##############################################################  Training  ##########################################################\n",
    "    #####  Parameters  ######################\n",
    "    num_features = len(df_sales[[i]].columns)\n",
    "    D_MODEL = optimal_d_model  \n",
    "    NUM_HEADS = optimal_num_head \n",
    "    NUM_LAYERS = optimal_num_layer \n",
    "    NUM_EPOCHS = 200\n",
    "    LR = 0.001\n",
    "    \n",
    "    #####Init the Model #######################\n",
    "    model = TransformerWithPE(num_features, num_features, D_MODEL, NUM_HEADS, NUM_LAYERS)\n",
    "    model.to(device)\n",
    "    early_stopper = utils.EarlyStopper(patience=20)\n",
    "    ##### Set Criterion Optimzer and scheduler ####################\n",
    "    criterion = torch.nn.MSELoss().to(device)    # mean-squared error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR,weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  patience=20,factor =0.1,min_lr=1e-7, eps=1e-08)\n",
    "    # Train the model\n",
    "    train_loss_, val_loss_ = [], []\n",
    "    for epoch in range(NUM_EPOCHS): \n",
    "        train_loss, val_loss = 0, 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "            pred = model(src.to(device), tgt.to(device))\n",
    "            loss = criterion(pred, tgt_y.to(device))\n",
    "            train_loss += loss.item()\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss/=len(train_loader.dataset)\n",
    "        train_loss_.append(train_loss)\n",
    "        #Evaluate on test     \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "                val = model(src.to(device), tgt.to(device))\n",
    "                loss = criterion(val, tgt_y.to(device))\n",
    "                val_loss += loss.item()\n",
    "        val_loss/=len(val_loader.dataset)\n",
    "        val_loss_.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "        if early_stopper.early_stop(val_loss, model, 'Models/transformer_final.pth'):\n",
    "            early_stopped = epoch+1\n",
    "            break\n",
    "    ##############################################################  Testing  ##########################################################\n",
    "    model = torch.load('Models/transformer_final.pth')\n",
    "    sequences_tensor = Variable(torch.Tensor(sequences))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src, tgt, tgt_y = split_sequence(sequences_tensor, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "        predicts_ = model(src.to(device), tgt.to(device))\n",
    "    predicts_ = predicts_.cpu().numpy().reshape(-1)\n",
    "    forecasts_ = np.zeros(28)\n",
    "    src = train_data_normalized[-optimal_sequence_length:]\n",
    "    src = Variable(torch.Tensor(src)).unsqueeze(0)\n",
    "    tgt_len = 1\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        forecasted = model.infer(src.to(device), tgt_len)\n",
    "    forecasts_[0] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "    for j in range(1, 28):\n",
    "        src = torch.cat((src[:, 1:].to(device), forecasted), dim = 1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecasted = model.infer(src.to(device), tgt_len)\n",
    "        forecasts_[j] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "    all_prediction = np.append(predicts_, forecasts_)\n",
    "    \n",
    "    sales_validation = pd.DataFrame(df_validation.iloc[:,i])\n",
    "    prediction_df[i] = scaler.inverse_transform(np.array(all_prediction).reshape(-1, 1)).reshape(-1)\n",
    "    rmse_train_lstm = np.sqrt(mean_squared_error(sales_validation[optimal_sequence_length:-28], prediction_df.iloc[:-28][i]))\n",
    "    r2_train_lstm = r2_score(sales_validation[optimal_sequence_length:-28], prediction_df.iloc[:-28][i])\n",
    "    rmse_test_lstm = np.sqrt(mean_squared_error(sales_validation[-28:], prediction_df.iloc[-28:][i]))\n",
    "    r2_test_lstm = r2_score(sales_validation[-28:], prediction_df.iloc[-28:][i])\n",
    "    time_taken = time.time() - start_time\n",
    "\n",
    "    summary_df.loc[i] = [rmse_train_lstm, r2_train_lstm, rmse_test_lstm, r2_test_lstm, time_taken]    \n",
    "    print(f\"Item {i} test rmse, test r2, time taken: {rmse_test_lstm}, {r2_test_lstm}, {time_taken}\")\n",
    "\n",
    "summary_df.to_csv(\"Baseline_transformer_Summary_3.csv\")\n",
    "prediction_df.to_csv(\"Baseline_transformer_Results_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c820e5a7-6625-4283-ac49-29b04be04684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
