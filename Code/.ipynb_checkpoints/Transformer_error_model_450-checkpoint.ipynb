{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28fd274-7727-4faa-b456-74dc5df06ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import time as time\n",
    "\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from pylab import rcParams\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset\n",
    "\n",
    "from utils import (\n",
    "    load_and_partition_data,\n",
    "    split_sequence\n",
    ")\n",
    "\n",
    "import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b590b7-ec9f-4f9c-bac8-4e90b4bb8f41",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f44658d3-cea9-45aa-ac89-893cc1e4c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"sales_train_validation.csv\")\n",
    "sell_prices = pd.read_csv(\"sell_prices.csv\")\n",
    "calendar = pd.read_csv(\"calendar.csv\")\n",
    "# validation contains 28 more dates\n",
    "validation = pd.read_csv(\"sales_train_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c950bb47-5834-4581-bead-43f806d17452",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cols = [c for c in train.columns if 'd_' in c]\n",
    "dates = calendar[calendar.d.isin(d_cols)]['date']\n",
    "dates_list = [datetime.strptime(date, '%Y-%m-%d').date() for date in dates]\n",
    "df_sales = train[d_cols].T\n",
    "df_sales.columns = train['id'].values\n",
    "df_sales = pd.DataFrame(df_sales).set_index([dates_list])\n",
    "df_sales.index = pd.to_datetime(df_sales.index)\n",
    "df_sales.columns = [i for i in range(len(df_sales.columns))]\n",
    "\n",
    "d_cols = [c for c in validation.columns if 'd_' in c]\n",
    "dates = calendar[calendar.d.isin(d_cols)]['date']\n",
    "dates_list = [datetime.strptime(date, '%Y-%m-%d').date() for date in dates]\n",
    "df_validation = validation[d_cols].T\n",
    "df_validation.columns = validation['id'].values\n",
    "df_validation = pd.DataFrame(df_validation).set_index([dates_list])\n",
    "df_validation.index = pd.to_datetime(df_validation.index)\n",
    "df_validation.columns = [i for i in range(len(df_validation.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a955f91d-2dcb-4815-a7ec-dedd3da5367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1345\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107f49a-b500-4db8-be2b-b4c110bb8a39",
   "metadata": {},
   "source": [
    "## Running Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df636e78-4718-4f14-8f44-84e6ee1de883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c903410-4872-4d9d-84ec-582a9582c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.pe[:, : x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerWithPE(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, in_dim: int, out_dim: int, embed_dim: int, num_heads: int, num_layers: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim)\n",
    "        self.encoder_embedding = torch.nn.Linear(\n",
    "            in_features=in_dim, out_features=embed_dim\n",
    "        )\n",
    "        self.decoder_embedding = torch.nn.Linear(\n",
    "            in_features=out_dim, out_features=embed_dim\n",
    "        )\n",
    "        self.output_layer = torch.nn.Linear(in_features=embed_dim, out_features=out_dim)\n",
    "        self.transformer = torch.nn.Transformer(\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            d_model=embed_dim,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, src: torch.Tensor, tgt: torch.Tensor) -> torch.Tensor:\n",
    "        # if self.train:\n",
    "        # Add noise to decoder inputs during training\n",
    "        # tgt = tgt + torch.normal(0, 0.1, size=tgt.shape).to(tgt.device)\n",
    "\n",
    "        # Embed encoder input and add positional encoding.\n",
    "        # [bs, src_seq_len, embed_dim]\n",
    "        src = self.encoder_embedding(src)\n",
    "        src = self.positional_encoding(src)\n",
    "\n",
    "        # Generate mask to avoid attention to future outputs.\n",
    "        # [tgt_seq_len, tgt_seq_len]\n",
    "        tgt_mask = torch.nn.Transformer.generate_square_subsequent_mask(tgt.shape[1])\n",
    "        # Embed decoder input and add positional encoding.\n",
    "        # [bs, tgt_seq_len, embed_dim]\n",
    "        tgt = self.decoder_embedding(tgt)\n",
    "        tgt = self.positional_encoding(tgt)\n",
    "\n",
    "        # Get prediction from transformer and map to output dimension.\n",
    "        # [bs, tgt_seq_len, embed_dim]\n",
    "        pred = self.transformer(src, tgt, tgt_mask=tgt_mask.to(device))\n",
    "        pred = self.output_layer(pred)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def infer(self, src: torch.Tensor, tgt_len: int) -> torch.Tensor:\n",
    "        output = torch.zeros((src.shape[0], tgt_len + 1, src.shape[2])).to(src.device)\n",
    "        output[:, 0] = src[:, -1]\n",
    "        for i in range(tgt_len):\n",
    "            output[:, i + 1] = self.forward(src, output)[:, i]\n",
    "\n",
    "        return output[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd15913-14cd-462d-826c-9d4720ea175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_batch_size = 32\n",
    "optimal_d_model = 64\n",
    "optimal_num_head = 4\n",
    "optimal_num_layer = 2\n",
    "optimal_sequence_length = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd556b96-9109-441d-881c-a37d8ced8d2e",
   "metadata": {},
   "source": [
    "### Batch 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb3b95d0-9a50-4bca-94b5-d2c171cca985",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = pd.read_csv(\"Baseline_transformer_Results_1.csv\")\n",
    "results1 = results1.iloc[:, 1:]\n",
    "results1.index = df_validation.index[optimal_sequence_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75888c0-f08f-4778-a595-756a462d5332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 2 test r2(pr), test r2(mu), time taken: -0.4572266356826966, -0.38677913103702943, 62.00556302070618\n",
      "Item 268 test r2(pr), test r2(mu), time taken: -0.019748091499781184, -0.05160965513894222, 25.518983602523804\n",
      "Item 345 test r2(pr), test r2(mu), time taken: -0.28420537082767305, -1.018158565068115, 40.21719288825989\n",
      "Item 380 test r2(pr), test r2(mu), time taken: -0.23837314121914766, -0.25064531753435215, 30.759873628616333\n",
      "Item 465 test r2(pr), test r2(mu), time taken: -0.20849677005533485, -0.19427787457403656, 29.76356840133667\n",
      "Item 478 test r2(pr), test r2(mu), time taken: -0.28746446131097403, -0.5553771468633992, 29.376527309417725\n",
      "Item 520 test r2(pr), test r2(mu), time taken: -0.24199676956041039, -0.2314286338463254, 41.96453833580017\n",
      "Item 529 test r2(pr), test r2(mu), time taken: -0.627303411357325, -0.6474059616092065, 37.351189613342285\n",
      "Item 569 test r2(pr), test r2(mu), time taken: -0.05014907584273587, -0.024964243633691208, 47.93453240394592\n",
      "Item 576 test r2(pr), test r2(mu), time taken: -0.33403826768102474, -0.34402532927029883, 35.787261962890625\n",
      "Item 657 test r2(pr), test r2(mu), time taken: 0.16301504557812474, -0.2609358593580482, 67.29759120941162\n",
      "Item 773 test r2(pr), test r2(mu), time taken: -0.13516884953382702, -0.11839467525663538, 29.42747163772583\n",
      "Item 783 test r2(pr), test r2(mu), time taken: -0.6152013373894836, -0.04341470175171902, 45.40186285972595\n",
      "Item 812 test r2(pr), test r2(mu), time taken: -0.01609948923941129, -0.016095503168782388, 18.396459817886353\n",
      "Item 888 test r2(pr), test r2(mu), time taken: -0.09054104759657466, -0.06436968655017994, 48.992892026901245\n",
      "Item 892 test r2(pr), test r2(mu), time taken: -3.286677082769927, -1.8797262922821307, 60.32884883880615\n",
      "Item 998 test r2(pr), test r2(mu), time taken: 0.0429389335900634, -0.03705042432119665, 20.895028352737427\n",
      "Item 1073 test r2(pr), test r2(mu), time taken: -0.554159985019339, -0.5291085781329117, 72.60258674621582\n",
      "Item 1085 test r2(pr), test r2(mu), time taken: -0.027200541697897762, -0.0852852402215527, 61.459506034851074\n",
      "Item 1087 test r2(pr), test r2(mu), time taken: -0.14116076872022187, -0.029426335385898783, 36.68199419975281\n",
      "Item 1102 test r2(pr), test r2(mu), time taken: -0.05636918781370115, -0.03404376112883001, 24.69436550140381\n",
      "Item 1159 test r2(pr), test r2(mu), time taken: -0.0998436090872703, -0.08036850723634403, 25.729961395263672\n",
      "Item 1163 test r2(pr), test r2(mu), time taken: -0.931039986787394, -0.890527497019397, 71.00902032852173\n",
      "Item 1170 test r2(pr), test r2(mu), time taken: 0.009726122425675165, -0.06338415768481087, 38.28748297691345\n",
      "Item 1172 test r2(pr), test r2(mu), time taken: -0.34120197845083156, -0.030182480713168314, 30.65099310874939\n",
      "Item 1220 test r2(pr), test r2(mu), time taken: -0.2931592053248935, -0.24442742346668833, 26.971619129180908\n",
      "Item 1235 test r2(pr), test r2(mu), time taken: -0.01593078443109719, -0.0727546270110564, 28.856662034988403\n",
      "Item 1236 test r2(pr), test r2(mu), time taken: -0.0031885892964345075, -0.0103916900223755, 26.318822860717773\n",
      "Item 1244 test r2(pr), test r2(mu), time taken: -0.5519123051831543, -0.464757452316249, 31.13228678703308\n",
      "Item 1343 test r2(pr), test r2(mu), time taken: -0.15734588430854202, -0.16552298918101727, 44.83580827713013\n",
      "Item 1383 test r2(pr), test r2(mu), time taken: -0.08651565509268178, -0.04222173356525172, 21.537574768066406\n",
      "Item 1453 test r2(pr), test r2(mu), time taken: -0.2011804468052607, -0.20292296184987846, 28.208529233932495\n",
      "Item 1464 test r2(pr), test r2(mu), time taken: -0.1898123170397359, 0.0013505465521439497, 76.56139945983887\n",
      "Item 1509 test r2(pr), test r2(mu), time taken: -0.31622331665558545, -0.29261277550077414, 24.82923460006714\n",
      "Item 1573 test r2(pr), test r2(mu), time taken: -0.23130492599729524, -0.21610219344149284, 27.862863063812256\n",
      "Item 1644 test r2(pr), test r2(mu), time taken: -0.13572598397037816, -0.12231034929440532, 20.515428066253662\n",
      "Item 1663 test r2(pr), test r2(mu), time taken: -0.03267623921015783, -0.20975328912800273, 54.45484256744385\n",
      "Item 1741 test r2(pr), test r2(mu), time taken: -3.3460486518003396, -0.026653086126016134, 50.4020938873291\n",
      "Item 1757 test r2(pr), test r2(mu), time taken: -0.014828491419513146, -0.013801961273914642, 32.01215314865112\n",
      "Item 1776 test r2(pr), test r2(mu), time taken: -0.07030378549819871, -0.14252445906269773, 59.39805340766907\n",
      "Item 1786 test r2(pr), test r2(mu), time taken: -0.4585737853622043, -0.044982016259815794, 36.53917646408081\n",
      "Item 1787 test r2(pr), test r2(mu), time taken: -0.06482744007009011, -0.06295273817223968, 23.697977781295776\n",
      "Item 1790 test r2(pr), test r2(mu), time taken: -0.21763047419367942, -0.3925373307759277, 39.60408806800842\n",
      "Item 1792 test r2(pr), test r2(mu), time taken: -3.058028265698117, -2.076090533109282, 62.621307373046875\n",
      "Item 1873 test r2(pr), test r2(mu), time taken: -0.1703298331398817, -0.13648574748286313, 23.482124090194702\n",
      "Item 1950 test r2(pr), test r2(mu), time taken: -0.006176467557517773, -0.008492985476339587, 26.00663995742798\n",
      "Item 2054 test r2(pr), test r2(mu), time taken: -0.299500321262137, -0.2510492621450273, 47.73028635978699\n",
      "Item 2066 test r2(pr), test r2(mu), time taken: -0.16812239420526098, -0.14066420067676066, 21.76812767982483\n",
      "Item 2068 test r2(pr), test r2(mu), time taken: -0.013697628614294022, -0.000405363198481945, 36.84714722633362\n",
      "Item 2076 test r2(pr), test r2(mu), time taken: -1.8348008406557206, -1.6661253537710947, 17.806811332702637\n",
      "Item 2134 test r2(pr), test r2(mu), time taken: -0.5176388979764333, -0.0032924589547331795, 30.350956201553345\n",
      "Item 2151 test r2(pr), test r2(mu), time taken: 0.03654090647275032, -0.027979982720368612, 37.50187849998474\n",
      "Item 2210 test r2(pr), test r2(mu), time taken: -0.0908809470432439, -0.09325983727281639, 59.83934688568115\n",
      "Item 2215 test r2(pr), test r2(mu), time taken: -0.6979177560249572, -0.7150705925596894, 44.644142150878906\n",
      "Item 2396 test r2(pr), test r2(mu), time taken: 0.006321374312213468, -0.07607721008241386, 61.66483497619629\n",
      "Item 2414 test r2(pr), test r2(mu), time taken: 0.004862419804944951, -0.05275284803382907, 51.04717397689819\n",
      "Item 2432 test r2(pr), test r2(mu), time taken: -0.5257905683942778, -0.14060619510618633, 42.067809104919434\n",
      "Item 2463 test r2(pr), test r2(mu), time taken: -0.039267763439833736, 0.003941706855267402, 41.125962257385254\n",
      "Item 2466 test r2(pr), test r2(mu), time taken: -0.18344339650248997, -0.006351274334295498, 26.96245789527893\n",
      "Item 2508 test r2(pr), test r2(mu), time taken: -0.7194406334754766, -0.7779047105186148, 22.602734088897705\n",
      "Item 2512 test r2(pr), test r2(mu), time taken: -0.14031944818367248, -1.319449922198853, 24.15924310684204\n",
      "Item 2523 test r2(pr), test r2(mu), time taken: -0.061682416882927305, -0.7817359662128711, 48.38956260681152\n",
      "Item 2557 test r2(pr), test r2(mu), time taken: -0.3474493268315293, -1.5304701166225003, 32.66243767738342\n",
      "Item 2572 test r2(pr), test r2(mu), time taken: -0.11095453565800528, -0.09852256298944462, 34.25165390968323\n",
      "Item 2601 test r2(pr), test r2(mu), time taken: 3.593276238800236e-05, -0.025182768530414457, 23.744801998138428\n",
      "Item 2627 test r2(pr), test r2(mu), time taken: -3.277329281019756, -2.969515198774846, 24.13395857810974\n",
      "Item 2690 test r2(pr), test r2(mu), time taken: 0.0, 0.0, 17.179227113723755\n",
      "Item 2716 test r2(pr), test r2(mu), time taken: -0.3072182104640613, -0.03217266809361963, 28.354942321777344\n",
      "Item 2731 test r2(pr), test r2(mu), time taken: -0.21806816116634087, -0.2863607963711243, 44.498913526535034\n",
      "Item 2746 test r2(pr), test r2(mu), time taken: -0.2788070548704069, -0.20566926174009614, 36.70823860168457\n",
      "Item 2836 test r2(pr), test r2(mu), time taken: -0.4221430873692249, -0.23362443466027827, 69.09515357017517\n",
      "Item 2880 test r2(pr), test r2(mu), time taken: -0.17171785309729493, -0.06958389054848957, 46.255823373794556\n",
      "Item 2901 test r2(pr), test r2(mu), time taken: -0.06272030242997806, -0.0294463686078541, 58.34090852737427\n",
      "Item 2913 test r2(pr), test r2(mu), time taken: 0.0016376165651726948, -0.04917664490323048, 30.88710045814514\n",
      "Item 2926 test r2(pr), test r2(mu), time taken: -0.2723564836543362, -0.7546343147539998, 38.73796844482422\n",
      "Item 2937 test r2(pr), test r2(mu), time taken: 0.1948978203641355, 0.5430772459581067, 52.11753535270691\n",
      "Item 2950 test r2(pr), test r2(mu), time taken: 0.0448914663973512, -0.09302417869903112, 60.86631989479065\n",
      "Item 2962 test r2(pr), test r2(mu), time taken: -2.4025852910684393, -1.3795412481580618, 32.02039456367493\n",
      "Item 2980 test r2(pr), test r2(mu), time taken: -0.39831909962033807, -0.1778548801150015, 41.616793155670166\n",
      "Item 2983 test r2(pr), test r2(mu), time taken: -0.11728707715328213, -0.12408786813005324, 44.73079013824463\n",
      "Item 2990 test r2(pr), test r2(mu), time taken: -0.061600156032074915, -0.0033453637444968987, 88.24102067947388\n",
      "Item 3033 test r2(pr), test r2(mu), time taken: 0.002931032106739284, -0.011194650770935288, 17.991063117980957\n",
      "Item 3036 test r2(pr), test r2(mu), time taken: -0.26232218384842, -0.3314343018471886, 24.149022102355957\n",
      "Item 3102 test r2(pr), test r2(mu), time taken: -0.36983020796093236, -0.3710802901674015, 31.304260730743408\n",
      "Item 3205 test r2(pr), test r2(mu), time taken: -0.4706090515778052, -0.48332725913923036, 45.85592007637024\n",
      "Item 3318 test r2(pr), test r2(mu), time taken: -0.01304426917702628, -0.017389975206536512, 39.006749629974365\n",
      "Item 3336 test r2(pr), test r2(mu), time taken: -0.8515035329303204, -0.8896512069203277, 29.120858430862427\n",
      "Item 3381 test r2(pr), test r2(mu), time taken: -1.1641289140875637, -0.06515501961803594, 59.71629738807678\n",
      "Item 3451 test r2(pr), test r2(mu), time taken: -0.5138526284134721, -0.5094877831793376, 30.98842191696167\n",
      "Item 3462 test r2(pr), test r2(mu), time taken: -0.2829090337304434, -0.1636955331197647, 34.64708209037781\n",
      "Item 3483 test r2(pr), test r2(mu), time taken: 0.0, 0.0, 23.647636651992798\n",
      "Item 3568 test r2(pr), test r2(mu), time taken: -0.1445988580591686, -0.1396883761300194, 32.169594049453735\n",
      "Item 3651 test r2(pr), test r2(mu), time taken: -1.9170515093347302, -0.13693899220782213, 40.36403679847717\n",
      "Item 3681 test r2(pr), test r2(mu), time taken: -0.04031551119477039, -0.09623802922127989, 28.361427068710327\n",
      "Item 3690 test r2(pr), test r2(mu), time taken: -0.5983340012747511, -0.5987230509871335, 34.140480518341064\n",
      "Item 3738 test r2(pr), test r2(mu), time taken: -0.10963764573833035, -0.04811188322886806, 20.022032737731934\n",
      "Item 3745 test r2(pr), test r2(mu), time taken: -1.6398981979808442, -1.5857966026431698, 18.72409200668335\n",
      "Item 3848 test r2(pr), test r2(mu), time taken: -0.8138666426422911, -0.8265306031857198, 85.46014904975891\n",
      "Item 3893 test r2(pr), test r2(mu), time taken: -0.3385882342629507, -0.32696640575641545, 29.277520656585693\n",
      "Item 3915 test r2(pr), test r2(mu), time taken: -0.36276127562976845, -0.36290969107956306, 26.551145553588867\n",
      "Item 4017 test r2(pr), test r2(mu), time taken: -0.033167550659775946, -0.08114763613260778, 24.040512561798096\n",
      "Item 4065 test r2(pr), test r2(mu), time taken: -0.011624471826822802, -0.283310594318126, 23.345594882965088\n",
      "Item 4155 test r2(pr), test r2(mu), time taken: -0.14092564003941987, -0.1304071473239703, 19.41320013999939\n",
      "Item 4178 test r2(pr), test r2(mu), time taken: -0.20666619177390944, -0.017665857801059337, 22.01393747329712\n",
      "Item 4209 test r2(pr), test r2(mu), time taken: -0.13283670276877002, -0.09137931140730426, 28.809450387954712\n",
      "Item 4259 test r2(pr), test r2(mu), time taken: -0.30319107587835536, -0.22844514447702324, 41.189518451690674\n",
      "Item 4278 test r2(pr), test r2(mu), time taken: -0.07040293578398482, -0.6269824308651666, 20.058712005615234\n",
      "Item 4280 test r2(pr), test r2(mu), time taken: -0.1258800169660097, -0.39579014810584034, 23.012497663497925\n",
      "Item 4318 test r2(pr), test r2(mu), time taken: -0.29277377019076534, -0.5376532537779466, 25.978594064712524\n",
      "Item 4323 test r2(pr), test r2(mu), time taken: -0.3364081027561643, -0.37424200579665645, 35.49942708015442\n",
      "Item 4424 test r2(pr), test r2(mu), time taken: -0.5324484505044906, -0.49771358550166744, 34.91780638694763\n",
      "Item 4523 test r2(pr), test r2(mu), time taken: -0.14951268577350985, -0.13456558688474418, 27.370529890060425\n",
      "Item 4573 test r2(pr), test r2(mu), time taken: -0.13126654522539938, -0.139611061257777, 37.87535643577576\n",
      "Item 4578 test r2(pr), test r2(mu), time taken: -0.1858479457381279, -0.393757192733202, 20.225745677947998\n",
      "Item 4622 test r2(pr), test r2(mu), time taken: -0.23149118256282453, -0.2678239785559571, 28.483733654022217\n",
      "Item 4712 test r2(pr), test r2(mu), time taken: 1.527321227567935e-05, 0.0004042068503441465, 24.16647243499756\n",
      "Item 4764 test r2(pr), test r2(mu), time taken: -0.08516493610467224, -0.13750176938928171, 32.355674743652344\n",
      "Item 4822 test r2(pr), test r2(mu), time taken: -0.22679505115040932, -0.03684967670801864, 62.774885416030884\n",
      "Item 4903 test r2(pr), test r2(mu), time taken: -0.1989403155600986, -0.1974256510286807, 24.179717540740967\n",
      "Item 4937 test r2(pr), test r2(mu), time taken: -0.03583758803732984, 0.09244368533697311, 33.38644528388977\n",
      "Item 4979 test r2(pr), test r2(mu), time taken: -0.6397610931126172, -0.45164460050643673, 61.27672052383423\n",
      "Item 5008 test r2(pr), test r2(mu), time taken: -0.5046002399879421, -0.45871543091545597, 33.371206283569336\n",
      "Item 5014 test r2(pr), test r2(mu), time taken: -0.2869884498259039, -0.37867642799190593, 67.01478385925293\n",
      "Item 5059 test r2(pr), test r2(mu), time taken: -0.6001086249455869, -0.2919810864959418, 41.03206276893616\n",
      "Item 5084 test r2(pr), test r2(mu), time taken: -0.5438374377903681, -0.5432324973742522, 35.13980460166931\n",
      "Item 5115 test r2(pr), test r2(mu), time taken: -0.25221552298756045, -0.5206353023187933, 19.129457235336304\n",
      "Item 5166 test r2(pr), test r2(mu), time taken: -0.03893334928244485, -0.19394826993639858, 48.14634132385254\n",
      "Item 5174 test r2(pr), test r2(mu), time taken: 0.00361703594939089, -0.09650589690173961, 60.484423875808716\n",
      "Item 5220 test r2(pr), test r2(mu), time taken: -0.7365814671518742, -0.9275982365444853, 24.20734190940857\n",
      "Item 5221 test r2(pr), test r2(mu), time taken: -3.267284815178816, -2.6554313862377645, 45.63116121292114\n",
      "Item 5223 test r2(pr), test r2(mu), time taken: -0.6460375282338628, -0.5308364731244708, 28.83522868156433\n",
      "Item 5240 test r2(pr), test r2(mu), time taken: -0.5862623399587565, -0.5344820573974711, 62.81484937667847\n",
      "Item 5257 test r2(pr), test r2(mu), time taken: -0.9737832343320534, -0.6985062175401715, 24.024680376052856\n",
      "Item 5352 test r2(pr), test r2(mu), time taken: -0.2845666103351656, -0.13293465657868442, 22.423529624938965\n",
      "Item 5375 test r2(pr), test r2(mu), time taken: 0.0, 0.0, 25.335152864456177\n",
      "Item 5467 test r2(pr), test r2(mu), time taken: -0.09983677041283667, -0.08630388899764085, 22.970453023910522\n",
      "Item 5473 test r2(pr), test r2(mu), time taken: -1.035187558168197, -0.910216161837877, 61.41005182266235\n",
      "Item 5477 test r2(pr), test r2(mu), time taken: -0.1405342970436314, -0.22754064371337046, 28.424920558929443\n",
      "Item 5482 test r2(pr), test r2(mu), time taken: -0.0456350138125583, -0.08559311713237694, 30.266838312149048\n",
      "Item 5528 test r2(pr), test r2(mu), time taken: -0.3912433909438453, -0.2475773241714856, 48.69753885269165\n",
      "Item 5546 test r2(pr), test r2(mu), time taken: -0.48809886483439624, -0.4732993643408936, 42.86716270446777\n",
      "Item 5622 test r2(pr), test r2(mu), time taken: -0.019444020215590996, 0.015092986439941725, 26.61328887939453\n",
      "Item 5787 test r2(pr), test r2(mu), time taken: 0.13440233193439344, -0.0342732914243109, 41.347413539886475\n",
      "Item 5845 test r2(pr), test r2(mu), time taken: -0.08458950260953313, -1.1288440175060304, 32.98510551452637\n",
      "Item 5847 test r2(pr), test r2(mu), time taken: -0.08743843977066423, -0.042356279627606686, 21.10912036895752\n",
      "Item 5880 test r2(pr), test r2(mu), time taken: -2.483927283272127, -0.11416065110183515, 51.49437642097473\n",
      "Item 5986 test r2(pr), test r2(mu), time taken: 0.5600223475890949, 0.5023808775969953, 28.41971492767334\n",
      "Item 5993 test r2(pr), test r2(mu), time taken: -0.5403674346010772, -0.6685046890229622, 26.519323587417603\n",
      "Item 6026 test r2(pr), test r2(mu), time taken: -0.0118008033516519, -0.15918925321924338, 47.057337045669556\n",
      "Item 6035 test r2(pr), test r2(mu), time taken: 0.0071657769697398566, -0.11544274765972373, 22.075366258621216\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(columns = [\"rmse_train_transformer_pr\", \"r2_train_transformer_pr\", \"rmse_test_transformer_pr\", \"r2_test_transformer_pr\", \"rmse_train_transformer_mu\", \"r2_train_transformer_mu\", \"rmse_test_transformer_mu\", \"r2_test_transformer_mu\", \"Time Taken\"])\n",
    "prediction_df_1 = pd.DataFrame()\n",
    "prediction_df_1.index = df_validation.index[optimal_sequence_length:]\n",
    "prediction_df_2 = pd.DataFrame()\n",
    "prediction_df_2.index = df_validation.index[optimal_sequence_length:]\n",
    "results = results1\n",
    "\n",
    "for string_i in results.columns: \n",
    "    \n",
    "    i = int(string_i)\n",
    "    start_time = time.time()\n",
    "\n",
    "    original_prediction_residuals_df = df_sales.iloc[optimal_sequence_length:, i] - results[string_i][:-28]\n",
    "    mu = original_prediction_residuals_df.mean()\n",
    "    total_residuals = [mu]*(optimal_sequence_length-1)+list(original_prediction_residuals_df)\n",
    "    total_residuals = np.array(total_residuals).reshape(len(total_residuals), 1)\n",
    "    total_residuals_df = pd.DataFrame(total_residuals)\n",
    "    total_residuals_df.index = df_sales.index[:-1]\n",
    "\n",
    "    y_scaler = MinMaxScaler((-1, 1))\n",
    "    r_scaler = MinMaxScaler((-1, 1))\n",
    "    y_scaler.fit(df_sales.iloc[:, i:i+1].values.reshape(-1, 1))\n",
    "    r_scaler.fit(total_residuals_df.values.reshape(-1, 1))\n",
    "    normalized_y = y_scaler.transform(df_sales.iloc[:-1, i:i+1])\n",
    "    normalized_r = r_scaler.transform(total_residuals_df)\n",
    "    train_data_normalized = np.concatenate([normalized_y, normalized_r], axis=1)\n",
    "    sequences = load_and_partition_data(train_data_normalized, optimal_sequence_length+1)\n",
    "    train_data = torch.tensor(np.array(sequences[:-28]), dtype=torch.float)\n",
    "    val_data = torch.tensor(np.array(sequences[-28:]), dtype=torch.float)\n",
    "    train_loader = DataLoader(train_data, batch_size=optimal_batch_size , shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=optimal_batch_size, shuffle=False, drop_last=False)\n",
    "    ##############################################################  Training  ##########################################################\n",
    "    #####  Parameters  ######################\n",
    "    num_features = len(train_data_normalized[0])\n",
    "    D_MODEL = optimal_d_model  \n",
    "    NUM_HEADS = optimal_num_head \n",
    "    NUM_LAYERS = optimal_num_layer \n",
    "    NUM_EPOCHS = 200\n",
    "    LR = 0.001\n",
    "    #####Init the Model #######################\n",
    "    model = TransformerWithPE(num_features, num_features, D_MODEL, NUM_HEADS, NUM_LAYERS)\n",
    "    model.to(device)\n",
    "    early_stopper = utils.EarlyStopper(patience=20)\n",
    "    ##### Set Criterion Optimzer and scheduler ####################\n",
    "    criterion = torch.nn.MSELoss().to(device)    # mean-squared error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR,weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  patience=20,factor =0.1 ,min_lr=1e-7, eps=1e-08)\n",
    "    # Train the model\n",
    "    train_loss_, val_loss_ = [], []\n",
    "    for epoch in range(NUM_EPOCHS): \n",
    "        train_loss, val_loss = 0, 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "            pred = model(src.to(device), tgt.to(device))\n",
    "            loss = criterion(pred, tgt_y.to(device))\n",
    "            train_loss += loss.item()\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss/=len(train_loader.dataset)\n",
    "        train_loss_.append(train_loss)\n",
    "        #Evaluate on test     \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "                val = model(src.to(device), tgt.to(device))\n",
    "                loss = criterion(val, tgt_y.to(device))\n",
    "                val_loss += loss.item()\n",
    "        val_loss/=len(val_loader.dataset)\n",
    "        val_loss_.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "        if early_stopper.early_stop(val_loss, model, 'Models/transformer_final_w_residuals.pth'):\n",
    "            early_stopped = epoch+1\n",
    "            break\n",
    "    ##############################################################  Testing 1  ##########################################################        break\n",
    "    model = torch.load('Models/transformer_final_w_residuals.pth')\n",
    "    sequences_tensor = Variable(torch.Tensor(sequences))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src, tgt, tgt_y = split_sequence(sequences_tensor, 28/29)\n",
    "        predicts_ = model(src.to(device), tgt.to(device))\n",
    "    predicts_ = predicts_.cpu().numpy().reshape(-1, 2)\n",
    "    forecasts_ = np.zeros((28, 2))\n",
    "    src = train_data_normalized[-optimal_sequence_length:]\n",
    "    src = Variable(torch.Tensor(src)).unsqueeze(0)\n",
    "    tgt_len = 1\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        forecasted = model.infer(src.to(device), tgt_len)\n",
    "    predicts_ = np.concatenate([predicts_, forecasted.cpu().data.numpy()[0]])\n",
    "    forecasted[0][0][0] = y_scaler.transform([[df_sales.iloc[-1, i]]])[0][0]\n",
    "    for j in range(28):\n",
    "        src = torch.cat((src[:, 1:].to(device), forecasted), dim = 1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecasted = model.infer(src.to(device), tgt_len)\n",
    "        forecasts_[j][0] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "        forecasts_[j][1] = forecasted.cpu().data.numpy()[0][0][1]\n",
    "    all_prediction = np.append(predicts_[:, 0], forecasts_[:, 0])\n",
    "\n",
    "    sales_validation = pd.DataFrame(df_validation.iloc[:,i])\n",
    "    \n",
    "    prediction_df_1[i] = y_scaler.inverse_transform(np.array(all_prediction).reshape(-1, 1)).reshape(-1)\n",
    "    rmse_train_lstm_1 = np.sqrt(mean_squared_error(sales_validation[optimal_sequence_length:-28], prediction_df_1.iloc[:-28][i]))\n",
    "    r2_train_lstm_1 = r2_score(sales_validation[optimal_sequence_length:-28], prediction_df_1.iloc[:-28][i])\n",
    "    rmse_test_lstm_1 = np.sqrt(mean_squared_error(sales_validation[-28:], prediction_df_1.iloc[-28:][i]))\n",
    "    r2_test_lstm_1 = r2_score(sales_validation[-28:], prediction_df_1.iloc[-28:][i])\n",
    "    ##############################################################  Testing 2  ##########################################################\n",
    "    sequences_tensor = Variable(torch.Tensor(sequences))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src, tgt, tgt_y = split_sequence(sequences_tensor, 28/29)\n",
    "        predicts_ = model(src.to(device), tgt.to(device))\n",
    "    predicts_ = predicts_.cpu().numpy().reshape(-1, 2)\n",
    "    forecasts_ = np.zeros((28, 2))\n",
    "    src = train_data_normalized[-optimal_sequence_length:]\n",
    "    src = Variable(torch.Tensor(src)).unsqueeze(0)\n",
    "    tgt_len = 1\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        forecasted = model.infer(src.to(device), tgt_len)\n",
    "    predicts_ = np.concatenate([predicts_, forecasted.cpu().data.numpy()[0]])\n",
    "    forecasted[0][0][0] = y_scaler.transform([[df_sales.iloc[-1, i]]])[0][0]\n",
    "    for j in range(28):\n",
    "        forecasted[0][0][1] = torch.tensor(r_scaler.transform([[mu]])[0][0]).to(device)\n",
    "        src = torch.cat((src[:, 1:].to(device), forecasted), dim = 1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecasted = model.infer(src.to(device), tgt_len)\n",
    "        forecasts_[j][0] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "        forecasts_[j][1] = forecasted.cpu().data.numpy()[0][0][1]\n",
    "    all_prediction = np.append(predicts_[:, 0], forecasts_[:, 0])\n",
    "    \n",
    "    prediction_df_2[i] = y_scaler.inverse_transform(np.array(all_prediction).reshape(-1, 1)).reshape(-1)\n",
    "    rmse_train_lstm_2 = np.sqrt(mean_squared_error(sales_validation[optimal_sequence_length:-28], prediction_df_2.iloc[:-28][i]))\n",
    "    r2_train_lstm_2 = r2_score(sales_validation[optimal_sequence_length:-28], prediction_df_2.iloc[:-28][i])\n",
    "    rmse_test_lstm_2 = np.sqrt(mean_squared_error(sales_validation[-28:], prediction_df_2.iloc[-28:][i]))\n",
    "    r2_test_lstm_2 = r2_score(sales_validation[-28:], prediction_df_2.iloc[-28:][i])\n",
    "    time_taken = time.time() - start_time\n",
    "\n",
    "    summary_df.loc[i] = [rmse_train_lstm_1, r2_train_lstm_1, rmse_test_lstm_1, r2_test_lstm_1, rmse_train_lstm_2, r2_train_lstm_2, rmse_test_lstm_2, r2_test_lstm_2, time_taken]    \n",
    "    print(f\"Item {i} test r2(pr), test r2(mu), time taken: {r2_test_lstm_1}, {r2_test_lstm_2}, {time_taken}\")\n",
    "\n",
    "\n",
    "summary_df.to_csv(\"Transformer_error_modelling_Summary_1.csv\")\n",
    "prediction_df_1.to_csv(\"Transformer_error_modelling_Results_1_1.csv\")\n",
    "prediction_df_2.to_csv(\"Transformer_error_modelling_Results_1_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31115748-b52e-48f3-b295-2b48ff45e300",
   "metadata": {},
   "source": [
    "### Batch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9998548-818f-4d76-9c8a-79878fb666f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.read_csv(\"Baseline_transformer_Results_2.csv\")\n",
    "results2 = results2.iloc[:, 1:]\n",
    "results2.index = df_validation.index[optimal_sequence_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b994f075-e4e7-443d-94c8-333a5d7912d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 6100 test r2(pr), test r2(mu), time taken: -0.22951782591004766, -0.21142702529061097, 19.55533242225647\n",
      "Item 6366 test r2(pr), test r2(mu), time taken: -0.2788048761388724, -0.3989091185389335, 42.336856842041016\n",
      "Item 6443 test r2(pr), test r2(mu), time taken: -0.25609705329119925, -0.06422524929257745, 32.28115367889404\n",
      "Item 6478 test r2(pr), test r2(mu), time taken: -0.22997247625210093, -0.20761939038207666, 33.776047468185425\n",
      "Item 6563 test r2(pr), test r2(mu), time taken: -0.04605290955320607, -0.024572877644703395, 31.01759934425354\n",
      "Item 6576 test r2(pr), test r2(mu), time taken: -1.103184482832134, -1.1386869283192658, 43.519251346588135\n",
      "Item 6618 test r2(pr), test r2(mu), time taken: -0.2418079754729403, -0.17738798519226395, 41.08570432662964\n",
      "Item 6627 test r2(pr), test r2(mu), time taken: -0.2794527274882823, -0.3055695363424429, 31.575950384140015\n",
      "Item 6667 test r2(pr), test r2(mu), time taken: -0.03238008706281459, -0.5385357598849316, 33.6034619808197\n",
      "Item 6674 test r2(pr), test r2(mu), time taken: -0.004790210700649, -0.03561461155839285, 36.40217089653015\n",
      "Item 6755 test r2(pr), test r2(mu), time taken: 0.07490041973576966, 0.10915979426122724, 53.89662528038025\n",
      "Item 6871 test r2(pr), test r2(mu), time taken: 0.0012952194219337798, -0.04369776125420044, 42.12409806251526\n",
      "Item 6881 test r2(pr), test r2(mu), time taken: -0.04936212542121399, -0.034313730799169884, 49.83750557899475\n",
      "Item 6910 test r2(pr), test r2(mu), time taken: 0.0, 0.0, 29.698259830474854\n",
      "Item 6986 test r2(pr), test r2(mu), time taken: -0.250186936251398, -0.6999277489933324, 35.365827560424805\n",
      "Item 6990 test r2(pr), test r2(mu), time taken: -3.8254959649568763, -1.9477504359725413, 32.95549154281616\n",
      "Item 7096 test r2(pr), test r2(mu), time taken: -0.07119225038008237, -0.18740224176983755, 29.349690914154053\n",
      "Item 7171 test r2(pr), test r2(mu), time taken: -0.07235960791749751, -0.3455563434719353, 43.24614977836609\n",
      "Item 7183 test r2(pr), test r2(mu), time taken: -0.5872652699483523, -0.33388159413275287, 37.59415578842163\n",
      "Item 7185 test r2(pr), test r2(mu), time taken: -0.2899674280075446, -0.5225935696920598, 25.98815679550171\n",
      "Item 7200 test r2(pr), test r2(mu), time taken: -0.40680112298493354, -0.39290404850161487, 49.51538634300232\n",
      "Item 7257 test r2(pr), test r2(mu), time taken: -0.11315180189666019, -0.007348353549402331, 21.497623443603516\n",
      "Item 7261 test r2(pr), test r2(mu), time taken: -0.3167454492393609, -0.023562145369090404, 36.56076097488403\n",
      "Item 7268 test r2(pr), test r2(mu), time taken: -0.018930284929120633, -0.19773298650773152, 35.22954511642456\n",
      "Item 7270 test r2(pr), test r2(mu), time taken: -0.13869644696682437, -0.3852454533328289, 24.20451307296753\n",
      "Item 7318 test r2(pr), test r2(mu), time taken: 0.0, 0.0, 26.68755865097046\n",
      "Item 7333 test r2(pr), test r2(mu), time taken: -0.6251088568420189, -0.20198758809798756, 25.882001399993896\n",
      "Item 7334 test r2(pr), test r2(mu), time taken: -0.014249076399527993, 0.00023767009263664374, 21.2750723361969\n",
      "Item 7342 test r2(pr), test r2(mu), time taken: -0.23008169412411084, -0.06184737429011111, 24.1104416847229\n",
      "Item 7441 test r2(pr), test r2(mu), time taken: 0.002213331125520135, -0.07320942847917244, 30.391578197479248\n",
      "Item 7481 test r2(pr), test r2(mu), time taken: -0.160600667642542, -0.011172118337534176, 20.66847825050354\n",
      "Item 7551 test r2(pr), test r2(mu), time taken: -0.2776089612869217, -0.28240985255984197, 32.50834369659424\n",
      "Item 7562 test r2(pr), test r2(mu), time taken: -0.6094094128591276, -0.30034389641566284, 17.87996530532837\n",
      "Item 7607 test r2(pr), test r2(mu), time taken: -0.1776601842191523, -0.02013863397062532, 39.951526165008545\n",
      "Item 7671 test r2(pr), test r2(mu), time taken: -0.23570790940087138, -0.315286670983175, 25.595133066177368\n",
      "Item 7742 test r2(pr), test r2(mu), time taken: -0.1920435070332116, -0.21601447617729508, 24.643963098526\n",
      "Item 7761 test r2(pr), test r2(mu), time taken: -0.5473629254923904, 0.00456195415175209, 27.419803857803345\n",
      "Item 7839 test r2(pr), test r2(mu), time taken: -0.5977854821973987, -0.5063358417996298, 22.700709342956543\n",
      "Item 7855 test r2(pr), test r2(mu), time taken: -0.22969401813175305, -0.19344874268024692, 33.597967863082886\n",
      "Item 7874 test r2(pr), test r2(mu), time taken: -0.21809015738310622, -0.0002924128389381053, 47.824817419052124\n",
      "Item 7884 test r2(pr), test r2(mu), time taken: -0.12384363083128558, -0.0005171584206740132, 31.997658014297485\n",
      "Item 7885 test r2(pr), test r2(mu), time taken: -0.34734960525658765, -1.5117363998086084, 63.986541748046875\n",
      "Item 7888 test r2(pr), test r2(mu), time taken: -0.10794533701193876, -0.0008825168149690921, 42.550616979599\n",
      "Item 7890 test r2(pr), test r2(mu), time taken: -0.5225454309646191, -0.176405758697467, 20.311182260513306\n",
      "Item 7971 test r2(pr), test r2(mu), time taken: -0.2442796140136161, -0.24457607545351356, 39.08862590789795\n",
      "Item 8048 test r2(pr), test r2(mu), time taken: -0.11334310243991541, 0.004349335559900913, 39.5429584980011\n",
      "Item 8152 test r2(pr), test r2(mu), time taken: -0.14588567099608407, -0.19990084507666506, 20.136133193969727\n",
      "Item 8164 test r2(pr), test r2(mu), time taken: -1.2473348312668096, -1.0734197782824189, 19.23900294303894\n",
      "Item 8166 test r2(pr), test r2(mu), time taken: -0.015413123127272943, -0.14661792558975129, 36.40104341506958\n",
      "Item 8174 test r2(pr), test r2(mu), time taken: -0.7967321218686088, -0.2293558284577395, 23.780776262283325\n",
      "Item 8232 test r2(pr), test r2(mu), time taken: -0.5674022205836193, -0.4113998144873372, 32.685020446777344\n",
      "Item 8249 test r2(pr), test r2(mu), time taken: -1.0074155034258498, -0.43368788650705326, 45.18570852279663\n",
      "Item 8308 test r2(pr), test r2(mu), time taken: -0.15038835917526594, -0.23171789344392146, 34.926575660705566\n",
      "Item 8313 test r2(pr), test r2(mu), time taken: -0.46143194900453954, -0.40330403984051966, 38.13431477546692\n",
      "Item 8494 test r2(pr), test r2(mu), time taken: -0.0031916837789722763, 0.008074106527888314, 68.73476266860962\n",
      "Item 8512 test r2(pr), test r2(mu), time taken: 0.08835944186726552, -0.002684859603533818, 44.643903732299805\n",
      "Item 8530 test r2(pr), test r2(mu), time taken: -0.028616390627753674, -0.002661065227383963, 54.553422689437866\n",
      "Item 8561 test r2(pr), test r2(mu), time taken: 0.00033629177271332633, -0.0003574316232568542, 17.36371946334839\n",
      "Item 8564 test r2(pr), test r2(mu), time taken: -0.09208757395483502, -0.3003792237779388, 77.81961131095886\n",
      "Item 8606 test r2(pr), test r2(mu), time taken: -0.5782201807110019, -0.6525408287696566, 33.99700212478638\n",
      "Item 8610 test r2(pr), test r2(mu), time taken: -0.13919268517785732, 0.13940173196826244, 28.410303592681885\n",
      "Item 8621 test r2(pr), test r2(mu), time taken: -0.08109839627860826, -0.020906835359146392, 40.592395305633545\n",
      "Item 8655 test r2(pr), test r2(mu), time taken: -0.04583817640865595, -4.971806918605832, 61.50293016433716\n",
      "Item 8670 test r2(pr), test r2(mu), time taken: -0.3505324994568131, -0.2979455666055564, 39.761539459228516\n",
      "Item 8699 test r2(pr), test r2(mu), time taken: -2.007807890163564, -0.5929095684538301, 44.07436537742615\n",
      "Item 8725 test r2(pr), test r2(mu), time taken: -0.03971294832079586, -0.09909456123374794, 55.75911021232605\n",
      "Item 8788 test r2(pr), test r2(mu), time taken: 0.0, 0.0, 29.626827001571655\n",
      "Item 8814 test r2(pr), test r2(mu), time taken: -0.5595705090752572, -0.2831746998141327, 66.8356626033783\n",
      "Item 8829 test r2(pr), test r2(mu), time taken: -0.13298546101839626, 0.02319657834109423, 41.04859805107117\n",
      "Item 8844 test r2(pr), test r2(mu), time taken: -0.038743831668266004, -0.06347638928394495, 60.15132427215576\n",
      "Item 8934 test r2(pr), test r2(mu), time taken: -0.18134012612884232, -0.28897336694566156, 26.111350536346436\n",
      "Item 8978 test r2(pr), test r2(mu), time taken: -3.7971375632185014, -1.8664711604155513, 24.485023260116577\n",
      "Item 8999 test r2(pr), test r2(mu), time taken: 0.033275739620099665, -0.019987794605196507, 21.42036271095276\n",
      "Item 9011 test r2(pr), test r2(mu), time taken: -0.4208552062278168, -1.502143870795834, 18.593996286392212\n",
      "Item 9024 test r2(pr), test r2(mu), time taken: -0.4719214382326624, -0.47222099615328084, 50.34398102760315\n",
      "Item 9035 test r2(pr), test r2(mu), time taken: -0.2336938746918351, -0.061026977458187526, 49.86827111244202\n",
      "Item 9048 test r2(pr), test r2(mu), time taken: -0.13731726248527965, -0.3988000301471064, 34.45431089401245\n",
      "Item 9060 test r2(pr), test r2(mu), time taken: -7.53439960049287, -3.473798437653649, 34.53062462806702\n",
      "Item 9078 test r2(pr), test r2(mu), time taken: -1.5041798528069132, -1.2064910390354773, 53.406763792037964\n",
      "Item 9081 test r2(pr), test r2(mu), time taken: 0.015095360259393398, -0.006632927241568609, 18.014589548110962\n",
      "Item 9088 test r2(pr), test r2(mu), time taken: -1.8428207159548884, -0.3766877584959276, 43.126495599746704\n",
      "Item 9131 test r2(pr), test r2(mu), time taken: -0.05526625401731389, -0.32618656667241197, 24.690269708633423\n",
      "Item 9134 test r2(pr), test r2(mu), time taken: -0.10939880087969489, -0.12971668936218794, 53.71296310424805\n",
      "Item 9200 test r2(pr), test r2(mu), time taken: -0.1567988315634441, -0.16029629812070678, 30.36678123474121\n",
      "Item 9303 test r2(pr), test r2(mu), time taken: -0.042547342385695464, -0.05141964072081584, 71.26127791404724\n",
      "Item 9416 test r2(pr), test r2(mu), time taken: -0.008739623918917694, -0.028261147701849954, 50.725539207458496\n",
      "Item 9434 test r2(pr), test r2(mu), time taken: -0.5357163122009723, -0.22192687364241825, 27.66886067390442\n",
      "Item 9479 test r2(pr), test r2(mu), time taken: -0.2714428182914179, -0.15521881887383504, 31.857701301574707\n",
      "Item 9549 test r2(pr), test r2(mu), time taken: -0.543094333470991, -0.5527607219310737, 24.02611017227173\n",
      "Item 9560 test r2(pr), test r2(mu), time taken: -0.0035421104586046415, -0.0009619088907433238, 33.75778269767761\n",
      "Item 9581 test r2(pr), test r2(mu), time taken: -0.11836125421898402, -0.11887521956400104, 73.93037700653076\n",
      "Item 9666 test r2(pr), test r2(mu), time taken: -0.16173312331099288, -0.17945806560045385, 25.241602659225464\n",
      "Item 9749 test r2(pr), test r2(mu), time taken: -0.030441645424217345, -0.3750375060785449, 32.21826148033142\n",
      "Item 9779 test r2(pr), test r2(mu), time taken: -0.17520190243590927, -0.06796638581228254, 41.43982458114624\n",
      "Item 9788 test r2(pr), test r2(mu), time taken: -0.20407414317346273, -0.6530310023416566, 22.350889444351196\n",
      "Item 9836 test r2(pr), test r2(mu), time taken: -0.00928911631419127, -0.039660659372622975, 19.603602170944214\n",
      "Item 9843 test r2(pr), test r2(mu), time taken: -0.8809844474884951, -0.23785151612894473, 28.17241907119751\n",
      "Item 9946 test r2(pr), test r2(mu), time taken: -0.4405025861148446, -0.43505154747579877, 20.642728328704834\n",
      "Item 9991 test r2(pr), test r2(mu), time taken: -0.43099664570796015, -0.4341563069085794, 45.43627595901489\n",
      "Item 10013 test r2(pr), test r2(mu), time taken: -0.42166515639288393, -0.4208899569592317, 89.30967044830322\n",
      "Item 10115 test r2(pr), test r2(mu), time taken: -0.21175502596191564, -0.03146607961544312, 21.829107999801636\n",
      "Item 10163 test r2(pr), test r2(mu), time taken: -0.10101474545805678, -0.1629569052899449, 54.141687870025635\n",
      "Item 10253 test r2(pr), test r2(mu), time taken: -0.16924911530211606, -0.16942907039998234, 49.79558277130127\n",
      "Item 10276 test r2(pr), test r2(mu), time taken: -0.049756954775848516, -0.08924720147344667, 26.43765878677368\n",
      "Item 10307 test r2(pr), test r2(mu), time taken: -0.12150778336202817, -0.361042971985331, 28.79091715812683\n",
      "Item 10357 test r2(pr), test r2(mu), time taken: -0.3322148283890365, -0.3321600619643108, 77.63772630691528\n",
      "Item 10376 test r2(pr), test r2(mu), time taken: 0.0, 0.0, 20.68107795715332\n",
      "Item 10378 test r2(pr), test r2(mu), time taken: -0.2291284796102815, -0.2263028244238936, 47.08850812911987\n",
      "Item 10416 test r2(pr), test r2(mu), time taken: -0.46054139025104823, -0.4641977188112032, 68.25255918502808\n",
      "Item 10421 test r2(pr), test r2(mu), time taken: -0.49573899079236106, -0.4413311096338006, 41.436975717544556\n",
      "Item 10522 test r2(pr), test r2(mu), time taken: -0.19718684335217773, -0.19495995343542516, 38.89081931114197\n",
      "Item 10621 test r2(pr), test r2(mu), time taken: -0.36083401977638685, -0.2911081965104818, 20.326529502868652\n",
      "Item 10671 test r2(pr), test r2(mu), time taken: -0.07064600033029333, -0.06957165185125769, 32.72803330421448\n",
      "Item 10676 test r2(pr), test r2(mu), time taken: -0.10149815867796086, -0.20589728433636845, 53.7543523311615\n",
      "Item 10720 test r2(pr), test r2(mu), time taken: -0.37759043418046523, -0.38211721175601165, 37.88161873817444\n",
      "Item 10810 test r2(pr), test r2(mu), time taken: -0.15575247395868308, -0.19039200238861542, 29.761760473251343\n",
      "Item 10862 test r2(pr), test r2(mu), time taken: -0.3163184229973135, -0.2666443734970365, 38.073521852493286\n",
      "Item 10920 test r2(pr), test r2(mu), time taken: -0.32663437425266895, -0.2656859583193236, 48.808098793029785\n",
      "Item 11001 test r2(pr), test r2(mu), time taken: -0.1514209398652442, -0.1290274682191288, 32.9641375541687\n",
      "Item 11035 test r2(pr), test r2(mu), time taken: -0.5281934847664989, -0.32570284673420846, 38.69406223297119\n",
      "Item 11077 test r2(pr), test r2(mu), time taken: -0.3048847739150089, -0.36662210473511836, 44.27336263656616\n",
      "Item 11106 test r2(pr), test r2(mu), time taken: 0.007341950925359608, -0.27672102478348504, 37.8908576965332\n",
      "Item 11112 test r2(pr), test r2(mu), time taken: 1.2489713451246942e-05, -0.005963478144683121, 24.014209985733032\n",
      "Item 11157 test r2(pr), test r2(mu), time taken: -0.9302485149545845, -0.934525439003733, 62.27157402038574\n",
      "Item 11182 test r2(pr), test r2(mu), time taken: -0.3759775013795341, -0.38132250115870714, 41.22786068916321\n",
      "Item 11213 test r2(pr), test r2(mu), time taken: -0.38933224230347196, -0.3908008010893216, 42.63152313232422\n",
      "Item 11264 test r2(pr), test r2(mu), time taken: -0.10957690471529502, -0.15205074834027088, 25.680813789367676\n",
      "Item 11272 test r2(pr), test r2(mu), time taken: -0.07158380201595205, -0.18636651349919542, 28.074878215789795\n",
      "Item 11318 test r2(pr), test r2(mu), time taken: -0.43621138979043184, -0.4784436008284394, 24.244860649108887\n",
      "Item 11319 test r2(pr), test r2(mu), time taken: -0.09124420654191256, -0.1970989053955059, 32.63012719154358\n",
      "Item 11321 test r2(pr), test r2(mu), time taken: -0.2873580228157169, -0.2779315073953572, 42.82059836387634\n",
      "Item 11338 test r2(pr), test r2(mu), time taken: -0.6176228061214646, -0.5382508205176615, 45.66023135185242\n",
      "Item 11355 test r2(pr), test r2(mu), time taken: -0.013020970683173427, -0.016257063768053914, 42.243367195129395\n",
      "Item 11450 test r2(pr), test r2(mu), time taken: 0.0005871578956621049, -0.9388842805424622, 23.911584615707397\n",
      "Item 11473 test r2(pr), test r2(mu), time taken: -0.10007656263367859, -0.02628289424592989, 39.00273108482361\n",
      "Item 11565 test r2(pr), test r2(mu), time taken: -0.000569035218271452, -0.17183966943407136, 41.5962347984314\n",
      "Item 11571 test r2(pr), test r2(mu), time taken: 0.10704319261349349, -0.16236779510287636, 22.0962336063385\n",
      "Item 11575 test r2(pr), test r2(mu), time taken: -0.04913966393416369, -0.12156755346155212, 20.22713541984558\n",
      "Item 11580 test r2(pr), test r2(mu), time taken: -0.7882863725838818, -0.8399622505572457, 73.20170402526855\n",
      "Item 11626 test r2(pr), test r2(mu), time taken: -0.6652976553242067, -0.6705109954360433, 25.166506052017212\n",
      "Item 11644 test r2(pr), test r2(mu), time taken: -0.27002362930155877, -0.23886188433786137, 23.564425468444824\n",
      "Item 11720 test r2(pr), test r2(mu), time taken: -0.05198149461094448, -0.03386452598507117, 91.0343565940857\n",
      "Item 11885 test r2(pr), test r2(mu), time taken: -0.2540900623716804, -0.39631799438686777, 35.597105503082275\n",
      "Item 11943 test r2(pr), test r2(mu), time taken: -0.1480967138526068, -0.06697475284301291, 29.911473989486694\n",
      "Item 11945 test r2(pr), test r2(mu), time taken: -0.63469094215672, -0.06183781832065538, 19.916914224624634\n",
      "Item 11978 test r2(pr), test r2(mu), time taken: -1.604891451231603, -0.24559299565673864, 30.35638403892517\n",
      "Item 12084 test r2(pr), test r2(mu), time taken: -0.221473193860227, -0.19767555897094624, 32.84368848800659\n",
      "Item 12091 test r2(pr), test r2(mu), time taken: -0.06489939874619521, -0.01595374675412331, 26.530449390411377\n",
      "Item 12124 test r2(pr), test r2(mu), time taken: -0.05881726242742791, -0.3763235936606486, 30.98869562149048\n",
      "Item 12133 test r2(pr), test r2(mu), time taken: -0.1293126878787516, -0.14681020322467564, 20.46315908432007\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(columns = [\"rmse_train_transformer_pr\", \"r2_train_transformer_pr\", \"rmse_test_transformer_pr\", \"r2_test_transformer_pr\", \"rmse_train_transformer_mu\", \"r2_train_transformer_mu\", \"rmse_test_transformer_mu\", \"r2_test_transformer_mu\", \"Time Taken\"])\n",
    "prediction_df_1 = pd.DataFrame()\n",
    "prediction_df_1.index = df_validation.index[optimal_sequence_length:]\n",
    "prediction_df_2 = pd.DataFrame()\n",
    "prediction_df_2.index = df_validation.index[optimal_sequence_length:]\n",
    "results = results2\n",
    "\n",
    "for string_i in results.columns: \n",
    "    \n",
    "    i = int(string_i)\n",
    "    start_time = time.time()\n",
    "\n",
    "    original_prediction_residuals_df = df_sales.iloc[optimal_sequence_length:, i] - results[string_i][:-28]\n",
    "    mu = original_prediction_residuals_df.mean()\n",
    "    total_residuals = [mu]*(optimal_sequence_length-1)+list(original_prediction_residuals_df)\n",
    "    total_residuals = np.array(total_residuals).reshape(len(total_residuals), 1)\n",
    "    total_residuals_df = pd.DataFrame(total_residuals)\n",
    "    total_residuals_df.index = df_sales.index[:-1]\n",
    "\n",
    "    y_scaler = MinMaxScaler((-1, 1))\n",
    "    r_scaler = MinMaxScaler((-1, 1))\n",
    "    y_scaler.fit(df_sales.iloc[:, i:i+1].values.reshape(-1, 1))\n",
    "    r_scaler.fit(total_residuals_df.values.reshape(-1, 1))\n",
    "    normalized_y = y_scaler.transform(df_sales.iloc[:-1, i:i+1])\n",
    "    normalized_r = r_scaler.transform(total_residuals_df)\n",
    "    train_data_normalized = np.concatenate([normalized_y, normalized_r], axis=1)\n",
    "    sequences = load_and_partition_data(train_data_normalized, optimal_sequence_length+1)\n",
    "    train_data = torch.tensor(np.array(sequences[:-28]), dtype=torch.float)\n",
    "    val_data = torch.tensor(np.array(sequences[-28:]), dtype=torch.float)\n",
    "    train_loader = DataLoader(train_data, batch_size=optimal_batch_size , shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=optimal_batch_size, shuffle=False, drop_last=False)\n",
    "    ##############################################################  Training  ##########################################################\n",
    "    #####  Parameters  ######################\n",
    "    num_features = len(train_data_normalized[0])\n",
    "    D_MODEL = optimal_d_model  \n",
    "    NUM_HEADS = optimal_num_head \n",
    "    NUM_LAYERS = optimal_num_layer \n",
    "    NUM_EPOCHS = 200\n",
    "    LR = 0.001\n",
    "    #####Init the Model #######################\n",
    "    model = TransformerWithPE(num_features, num_features, D_MODEL, NUM_HEADS, NUM_LAYERS)\n",
    "    model.to(device)\n",
    "    early_stopper = utils.EarlyStopper(patience=20)\n",
    "    ##### Set Criterion Optimzer and scheduler ####################\n",
    "    criterion = torch.nn.MSELoss().to(device)    # mean-squared error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR,weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  patience=20,factor =0.1 ,min_lr=1e-7, eps=1e-08)\n",
    "    # Train the model\n",
    "    train_loss_, val_loss_ = [], []\n",
    "    for epoch in range(NUM_EPOCHS): \n",
    "        train_loss, val_loss = 0, 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "            pred = model(src.to(device), tgt.to(device))\n",
    "            loss = criterion(pred, tgt_y.to(device))\n",
    "            train_loss += loss.item()\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss/=len(train_loader.dataset)\n",
    "        train_loss_.append(train_loss)\n",
    "        #Evaluate on test     \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "                val = model(src.to(device), tgt.to(device))\n",
    "                loss = criterion(val, tgt_y.to(device))\n",
    "                val_loss += loss.item()\n",
    "        val_loss/=len(val_loader.dataset)\n",
    "        val_loss_.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "        if early_stopper.early_stop(val_loss, model, 'Models/transformer_final_w_residuals.pth'):\n",
    "            early_stopped = epoch+1\n",
    "            break\n",
    "    ##############################################################  Testing 1  ##########################################################        break\n",
    "    model = torch.load('Models/transformer_final_w_residuals.pth')\n",
    "    sequences_tensor = Variable(torch.Tensor(sequences))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src, tgt, tgt_y = split_sequence(sequences_tensor, 28/29)\n",
    "        predicts_ = model(src.to(device), tgt.to(device))\n",
    "    predicts_ = predicts_.cpu().numpy().reshape(-1, 2)\n",
    "    forecasts_ = np.zeros((28, 2))\n",
    "    src = train_data_normalized[-optimal_sequence_length:]\n",
    "    src = Variable(torch.Tensor(src)).unsqueeze(0)\n",
    "    tgt_len = 1\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        forecasted = model.infer(src.to(device), tgt_len)\n",
    "    predicts_ = np.concatenate([predicts_, forecasted.cpu().data.numpy()[0]])\n",
    "    forecasted[0][0][0] = y_scaler.transform([[df_sales.iloc[-1, i]]])[0][0]\n",
    "    for j in range(28):\n",
    "        src = torch.cat((src[:, 1:].to(device), forecasted), dim = 1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecasted = model.infer(src.to(device), tgt_len)\n",
    "        forecasts_[j][0] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "        forecasts_[j][1] = forecasted.cpu().data.numpy()[0][0][1]\n",
    "    all_prediction = np.append(predicts_[:, 0], forecasts_[:, 0])\n",
    "\n",
    "    sales_validation = pd.DataFrame(df_validation.iloc[:,i])\n",
    "    \n",
    "    prediction_df_1[i] = y_scaler.inverse_transform(np.array(all_prediction).reshape(-1, 1)).reshape(-1)\n",
    "    rmse_train_lstm_1 = np.sqrt(mean_squared_error(sales_validation[optimal_sequence_length:-28], prediction_df_1.iloc[:-28][i]))\n",
    "    r2_train_lstm_1 = r2_score(sales_validation[optimal_sequence_length:-28], prediction_df_1.iloc[:-28][i])\n",
    "    rmse_test_lstm_1 = np.sqrt(mean_squared_error(sales_validation[-28:], prediction_df_1.iloc[-28:][i]))\n",
    "    r2_test_lstm_1 = r2_score(sales_validation[-28:], prediction_df_1.iloc[-28:][i])\n",
    "    ##############################################################  Testing 2  ##########################################################\n",
    "    sequences_tensor = Variable(torch.Tensor(sequences))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src, tgt, tgt_y = split_sequence(sequences_tensor, 28/29)\n",
    "        predicts_ = model(src.to(device), tgt.to(device))\n",
    "    predicts_ = predicts_.cpu().numpy().reshape(-1, 2)\n",
    "    forecasts_ = np.zeros((28, 2))\n",
    "    src = train_data_normalized[-optimal_sequence_length:]\n",
    "    src = Variable(torch.Tensor(src)).unsqueeze(0)\n",
    "    tgt_len = 1\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        forecasted = model.infer(src.to(device), tgt_len)\n",
    "    predicts_ = np.concatenate([predicts_, forecasted.cpu().data.numpy()[0]])\n",
    "    forecasted[0][0][0] = y_scaler.transform([[df_sales.iloc[-1, i]]])[0][0]\n",
    "    for j in range(28):\n",
    "        forecasted[0][0][1] = torch.tensor(r_scaler.transform([[mu]])[0][0]).to(device)\n",
    "        src = torch.cat((src[:, 1:].to(device), forecasted), dim = 1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecasted = model.infer(src.to(device), tgt_len)\n",
    "        forecasts_[j][0] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "        forecasts_[j][1] = forecasted.cpu().data.numpy()[0][0][1]\n",
    "    all_prediction = np.append(predicts_[:, 0], forecasts_[:, 0])\n",
    "    \n",
    "    prediction_df_2[i] = y_scaler.inverse_transform(np.array(all_prediction).reshape(-1, 1)).reshape(-1)\n",
    "    rmse_train_lstm_2 = np.sqrt(mean_squared_error(sales_validation[optimal_sequence_length:-28], prediction_df_2.iloc[:-28][i]))\n",
    "    r2_train_lstm_2 = r2_score(sales_validation[optimal_sequence_length:-28], prediction_df_2.iloc[:-28][i])\n",
    "    rmse_test_lstm_2 = np.sqrt(mean_squared_error(sales_validation[-28:], prediction_df_2.iloc[-28:][i]))\n",
    "    r2_test_lstm_2 = r2_score(sales_validation[-28:], prediction_df_2.iloc[-28:][i])\n",
    "    time_taken = time.time() - start_time\n",
    "\n",
    "    summary_df.loc[i] = [rmse_train_lstm_1, r2_train_lstm_1, rmse_test_lstm_1, r2_test_lstm_1, rmse_train_lstm_2, r2_train_lstm_2, rmse_test_lstm_2, r2_test_lstm_2, time_taken]    \n",
    "    print(f\"Item {i} test r2(pr), test r2(mu), time taken: {r2_test_lstm_1}, {r2_test_lstm_2}, {time_taken}\")\n",
    "\n",
    "summary_df.to_csv(\"Transformer_error_modelling_Summary_2.csv\")\n",
    "prediction_df_1.to_csv(\"Transformer_error_modelling_Results_2_1.csv\")\n",
    "prediction_df_2.to_csv(\"Transformer_error_modelling_Results_2_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f777428b-c64f-43ff-9a12-575b177e7209",
   "metadata": {},
   "source": [
    "### Batch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc652b98-a2ed-4e14-8c78-ecfb640bd6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = pd.read_csv(\"Baseline_transformer_Results_3.csv\")\n",
    "results3 = results3.iloc[:, 1:]\n",
    "results3.index = df_validation.index[optimal_sequence_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8e4141d-4afe-4343-8df9-152ac49913b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 12269 test r2(pr), test r2(mu), time taken: -0.346587183162123, -0.6128355778685319, 21.31509804725647\n",
      "Item 12274 test r2(pr), test r2(mu), time taken: -0.16606068016396436, -0.16667339173268814, 28.31914782524109\n",
      "Item 12308 test r2(pr), test r2(mu), time taken: 0.0, 0.0, 45.57865238189697\n",
      "Item 12314 test r2(pr), test r2(mu), time taken: -0.15652431175403936, -0.12927761654269077, 25.127774477005005\n",
      "Item 12342 test r2(pr), test r2(mu), time taken: -0.011697271834518963, -0.018647401108710104, 23.55124807357788\n",
      "Item 12363 test r2(pr), test r2(mu), time taken: -0.12889761420239987, -0.09692135776371247, 31.76591920852661\n",
      "Item 12466 test r2(pr), test r2(mu), time taken: -0.05278446340332299, -0.008100617530055976, 28.664662837982178\n",
      "Item 12490 test r2(pr), test r2(mu), time taken: -0.001956009029135508, -0.0004993643424890948, 23.0234375\n",
      "Item 12493 test r2(pr), test r2(mu), time taken: -0.3064072394130417, -0.3053770070742996, 47.81609344482422\n",
      "Item 12552 test r2(pr), test r2(mu), time taken: 0.0, 0.0, 29.127740144729614\n",
      "Item 12599 test r2(pr), test r2(mu), time taken: -0.04336998134262138, -0.288342631693284, 42.24510169029236\n",
      "Item 12618 test r2(pr), test r2(mu), time taken: -0.4252640246518802, -0.4205467011742494, 46.2103705406189\n",
      "Item 12672 test r2(pr), test r2(mu), time taken: -0.08992243673279376, -0.034984736563454355, 18.504271745681763\n",
      "Item 12675 test r2(pr), test r2(mu), time taken: -0.11045702467681418, -0.12419603247470912, 34.795629262924194\n",
      "Item 12684 test r2(pr), test r2(mu), time taken: -0.2004950049163874, -0.20315251123082279, 34.28072547912598\n",
      "Item 12693 test r2(pr), test r2(mu), time taken: -0.10360578658961295, -0.1044029559834887, 62.19000840187073\n",
      "Item 12694 test r2(pr), test r2(mu), time taken: 0.0, 0.0, 41.05174374580383\n",
      "Item 12696 test r2(pr), test r2(mu), time taken: -0.5304479800090367, -0.5215497744082254, 38.98651146888733\n",
      "Item 12756 test r2(pr), test r2(mu), time taken: -0.23498743242857167, -0.15789556568478602, 43.49077486991882\n",
      "Item 12796 test r2(pr), test r2(mu), time taken: -0.3902346541489672, -0.3843409466485599, 34.84870648384094\n",
      "Item 12806 test r2(pr), test r2(mu), time taken: -0.05377345368492614, -0.012443598325093896, 21.121252298355103\n",
      "Item 12842 test r2(pr), test r2(mu), time taken: -0.09158052670028138, -0.08083117972029563, 23.498101472854614\n",
      "Item 12860 test r2(pr), test r2(mu), time taken: -0.017220869499518177, -0.6914834230020273, 26.286248922348022\n",
      "Item 12924 test r2(pr), test r2(mu), time taken: -0.6958975311037365, -0.030366695211893058, 28.396808385849\n",
      "Item 12932 test r2(pr), test r2(mu), time taken: -0.0750407273443714, -0.027272243080958658, 28.846351623535156\n",
      "Item 12940 test r2(pr), test r2(mu), time taken: -0.9074887753843477, -0.7974386110482334, 40.57216143608093\n",
      "Item 12988 test r2(pr), test r2(mu), time taken: -0.043186357446673096, -0.338745191117825, 33.01841926574707\n",
      "Item 13004 test r2(pr), test r2(mu), time taken: -1.1564938006975178, -1.0515192788837537, 43.07572364807129\n",
      "Item 13009 test r2(pr), test r2(mu), time taken: -0.0032892549575762597, 0.06442020544247384, 30.922533750534058\n",
      "Item 13013 test r2(pr), test r2(mu), time taken: -0.19668846111716243, -0.2091106397257716, 32.590667963027954\n",
      "Item 13130 test r2(pr), test r2(mu), time taken: -0.21622607149260897, -0.03134692994675281, 33.900092363357544\n",
      "Item 13200 test r2(pr), test r2(mu), time taken: -0.02745496845852724, -0.1525318101691937, 50.06660556793213\n",
      "Item 13328 test r2(pr), test r2(mu), time taken: -0.2583466945751507, -0.1623167976332458, 35.95603132247925\n",
      "Item 13423 test r2(pr), test r2(mu), time taken: -0.1628586630940645, -0.14849732744177957, 31.93301224708557\n",
      "Item 13436 test r2(pr), test r2(mu), time taken: -0.2719879687336233, -0.2889302054509888, 25.17606496810913\n",
      "Item 13634 test r2(pr), test r2(mu), time taken: -0.3029375141643498, -0.30783335409060597, 58.32927656173706\n",
      "Item 13645 test r2(pr), test r2(mu), time taken: -0.10951771746657024, -0.13798916055053212, 44.55222821235657\n",
      "Item 13686 test r2(pr), test r2(mu), time taken: -0.10103481921666702, -0.04635969783287264, 29.71933627128601\n",
      "Item 13753 test r2(pr), test r2(mu), time taken: -0.2053899202481344, -0.20035527588301894, 17.189810514450073\n",
      "Item 13763 test r2(pr), test r2(mu), time taken: -0.24273634586982662, -0.08522335743356835, 35.06358528137207\n",
      "Item 13786 test r2(pr), test r2(mu), time taken: -0.2895670013055902, -0.2903711958891231, 33.27469873428345\n",
      "Item 13836 test r2(pr), test r2(mu), time taken: -0.559682583909134, -0.566748001980306, 60.58500003814697\n",
      "Item 13888 test r2(pr), test r2(mu), time taken: -0.73544314470922, -0.6248701216896455, 31.785764932632446\n",
      "Item 13910 test r2(pr), test r2(mu), time taken: -0.09334332325040773, -0.17097407585091173, 34.96906876564026\n",
      "Item 13951 test r2(pr), test r2(mu), time taken: -0.6057193532086782, -0.5607439417546594, 74.74494314193726\n",
      "Item 13956 test r2(pr), test r2(mu), time taken: -0.4937198768057416, -0.40571157901708044, 50.08286762237549\n",
      "Item 13957 test r2(pr), test r2(mu), time taken: -0.7648372932617185, -0.2822412333976081, 48.465773820877075\n",
      "Item 14044 test r2(pr), test r2(mu), time taken: -0.11675865053105716, -0.022860415127219147, 19.226441621780396\n",
      "Item 14051 test r2(pr), test r2(mu), time taken: -0.08764834090765272, -0.21243389281546765, 27.88245463371277\n",
      "Item 14064 test r2(pr), test r2(mu), time taken: -0.39203284637791413, -0.703943614831662, 37.961137533187866\n",
      "Item 14116 test r2(pr), test r2(mu), time taken: -0.12015290354370567, -0.22219628919472156, 20.473734140396118\n",
      "Item 14170 test r2(pr), test r2(mu), time taken: -0.17609190961249, -0.13603874969231877, 26.32912039756775\n",
      "Item 14221 test r2(pr), test r2(mu), time taken: -0.0368622128483167, -0.03173615493136617, 42.79112672805786\n",
      "Item 14346 test r2(pr), test r2(mu), time taken: -0.2265150397785498, -0.22297251884456282, 51.41440415382385\n",
      "Item 14382 test r2(pr), test r2(mu), time taken: -0.04750921268288821, -0.030208078164711605, 22.251996994018555\n",
      "Item 14387 test r2(pr), test r2(mu), time taken: -0.1330023951876671, -0.37481637596328166, 30.204256057739258\n",
      "Item 14389 test r2(pr), test r2(mu), time taken: -0.21237389266304718, -0.46025929902049834, 27.962971925735474\n",
      "Item 14452 test r2(pr), test r2(mu), time taken: -0.20520815159248929, -0.19861273490915843, 26.82451581954956\n",
      "Item 14472 test r2(pr), test r2(mu), time taken: -0.6224964405865729, -0.2891772387463374, 37.594013690948486\n",
      "Item 14477 test r2(pr), test r2(mu), time taken: -0.12458058222103485, -0.027249773800443133, 43.250028133392334\n",
      "Item 14487 test r2(pr), test r2(mu), time taken: -0.041966708617515947, -0.08848028577580935, 30.291752099990845\n",
      "Item 14562 test r2(pr), test r2(mu), time taken: -0.3595957415131188, -0.2548112669589704, 30.567962884902954\n",
      "Item 14568 test r2(pr), test r2(mu), time taken: -0.0026605448459118275, -0.052581178707491905, 25.455030918121338\n",
      "Item 14600 test r2(pr), test r2(mu), time taken: -0.43173900520278097, -0.4376376383203815, 59.9633572101593\n",
      "Item 14604 test r2(pr), test r2(mu), time taken: -0.1730587707106197, -0.019492994404293196, 28.927195072174072\n",
      "Item 14688 test r2(pr), test r2(mu), time taken: -0.02905398275954285, -0.014656787070102872, 20.895930290222168\n",
      "Item 14697 test r2(pr), test r2(mu), time taken: -1.757017824266371, -1.3518031177422998, 38.90195560455322\n",
      "Item 14856 test r2(pr), test r2(mu), time taken: -0.24671137762742434, -0.24818460936195263, 23.62163734436035\n",
      "Item 14894 test r2(pr), test r2(mu), time taken: -0.6499440936627401, 0.23881132411696016, 48.65049505233765\n",
      "Item 14916 test r2(pr), test r2(mu), time taken: -0.5044998630559008, -0.8888645420987349, 23.16153073310852\n",
      "Item 14938 test r2(pr), test r2(mu), time taken: -0.4366342627858264, -0.4325212083870227, 48.86975836753845\n",
      "Item 14940 test r2(pr), test r2(mu), time taken: -0.01615909666305071, -0.1397079181099048, 45.36326885223389\n",
      "Item 14969 test r2(pr), test r2(mu), time taken: -0.11151532173841439, -0.05772933978336381, 18.0712833404541\n",
      "Item 15033 test r2(pr), test r2(mu), time taken: -0.09523280523549071, -0.10175975242935054, 22.272942781448364\n",
      "Item 15053 test r2(pr), test r2(mu), time taken: -0.1783214826714694, -0.1785181926119659, 79.62465119361877\n",
      "Item 15074 test r2(pr), test r2(mu), time taken: -0.24319979643981227, -0.054211846834137045, 35.523295879364014\n",
      "Item 15116 test r2(pr), test r2(mu), time taken: -0.3044931643656734, -0.29781240123863517, 34.03113627433777\n",
      "Item 15231 test r2(pr), test r2(mu), time taken: 0.009735112817928715, -0.4262800484835545, 46.80546855926514\n",
      "Item 15248 test r2(pr), test r2(mu), time taken: -0.08884637356775826, -0.03311860781528586, 21.36325192451477\n",
      "Item 15255 test r2(pr), test r2(mu), time taken: -0.2534612343552487, -0.24503606725642513, 32.7667760848999\n",
      "Item 15298 test r2(pr), test r2(mu), time taken: 0.0, 0.0, 34.420207023620605\n",
      "Item 15301 test r2(pr), test r2(mu), time taken: -0.5994708530012443, -0.19484994269724454, 42.88849902153015\n",
      "Item 15383 test r2(pr), test r2(mu), time taken: -0.19195257549884848, -0.2082801746012508, 30.9118869304657\n",
      "Item 15439 test r2(pr), test r2(mu), time taken: -0.008351287198867796, -0.018779127611043167, 26.568048000335693\n",
      "Item 15441 test r2(pr), test r2(mu), time taken: -0.1769832608184112, -0.15619825593431003, 30.726908922195435\n",
      "Item 15477 test r2(pr), test r2(mu), time taken: -0.14926023453871662, -0.3675197869249882, 21.431999921798706\n",
      "Item 15620 test r2(pr), test r2(mu), time taken: -0.2020940395530102, -0.1494661435663669, 27.690641403198242\n",
      "Item 15668 test r2(pr), test r2(mu), time taken: -0.13626588161315834, -0.1499953269797718, 34.16900110244751\n",
      "Item 15707 test r2(pr), test r2(mu), time taken: -0.36144164002923995, -0.3381749886528955, 34.81575536727905\n",
      "Item 15810 test r2(pr), test r2(mu), time taken: -0.1899331267290698, -0.06933429627288623, 20.129101991653442\n",
      "Item 15853 test r2(pr), test r2(mu), time taken: -0.14576674730577488, -0.01913149345973042, 46.35030746459961\n",
      "Item 15868 test r2(pr), test r2(mu), time taken: -0.03918087567764306, -0.09772567417297817, 36.70466089248657\n",
      "Item 15971 test r2(pr), test r2(mu), time taken: -0.009409532130591591, -0.11392390099187377, 57.945616245269775\n",
      "Item 16001 test r2(pr), test r2(mu), time taken: -0.47634023647172596, -0.1587961298078706, 22.06800866127014\n",
      "Item 16029 test r2(pr), test r2(mu), time taken: -0.2711972964095628, -0.5823395236656694, 20.347790479660034\n",
      "Item 16045 test r2(pr), test r2(mu), time taken: -0.003772700239854876, -0.23746610283706504, 27.109717845916748\n",
      "Item 16135 test r2(pr), test r2(mu), time taken: -0.3765737563380882, -0.4158182297075561, 48.613717555999756\n",
      "Item 16140 test r2(pr), test r2(mu), time taken: -0.12873790104054428, -0.12917586518105417, 56.41955614089966\n",
      "Item 16191 test r2(pr), test r2(mu), time taken: -0.32372322242826157, -0.4253107250335393, 34.68995642662048\n",
      "Item 16249 test r2(pr), test r2(mu), time taken: -0.1124804594327442, -0.02971488534945288, 39.995930910110474\n",
      "Item 16307 test r2(pr), test r2(mu), time taken: -0.02487592794092608, -0.03962197570356718, 57.30330729484558\n",
      "Item 16314 test r2(pr), test r2(mu), time taken: -0.0025812809382768087, -0.008576390392881272, 41.221946716308594\n",
      "Item 16514 test r2(pr), test r2(mu), time taken: -0.21064738626815993, -0.19564910307379546, 19.838892936706543\n",
      "Item 16557 test r2(pr), test r2(mu), time taken: -0.18193150829594962, -0.1981452829308501, 69.40623688697815\n",
      "Item 16579 test r2(pr), test r2(mu), time taken: -0.48311044431104766, -0.1213643819085819, 48.846014976501465\n",
      "Item 16624 test r2(pr), test r2(mu), time taken: -0.18810130483784127, -0.17565202410407976, 39.415761947631836\n",
      "Item 16626 test r2(pr), test r2(mu), time taken: -0.24846993595107536, -0.15482083779334488, 91.4610550403595\n",
      "Item 16652 test r2(pr), test r2(mu), time taken: -0.45280774106587685, -0.3183935906825599, 26.284173488616943\n",
      "Item 16661 test r2(pr), test r2(mu), time taken: -0.4145701587185058, -0.38959758532133004, 34.82565450668335\n",
      "Item 16686 test r2(pr), test r2(mu), time taken: 0.030795794450463876, -0.012421473323378729, 68.6560845375061\n",
      "Item 16695 test r2(pr), test r2(mu), time taken: -0.0026924137880612875, -0.009817730671686231, 18.43819260597229\n",
      "Item 16726 test r2(pr), test r2(mu), time taken: -0.18204443882075916, -0.18575694548983646, 29.38775110244751\n",
      "Item 16751 test r2(pr), test r2(mu), time taken: -0.8969595990141186, -0.5179750955386602, 47.876837491989136\n",
      "Item 16801 test r2(pr), test r2(mu), time taken: -0.21201002109711764, -0.19826225441985068, 20.268662452697754\n",
      "Item 16831 test r2(pr), test r2(mu), time taken: -0.20159255324040326, -0.4299450488309813, 35.42604160308838\n",
      "Item 16865 test r2(pr), test r2(mu), time taken: -0.13570362564298888, -0.01945934305058472, 64.3705952167511\n",
      "Item 16885 test r2(pr), test r2(mu), time taken: -0.3333879355031988, -0.41712075988623987, 35.336181640625\n",
      "Item 16925 test r2(pr), test r2(mu), time taken: -0.2438211418571521, -0.19820298710682782, 109.79254460334778\n",
      "Item 16960 test r2(pr), test r2(mu), time taken: -0.07834826591595667, -0.10641129476796252, 39.136868953704834\n",
      "Item 16967 test r2(pr), test r2(mu), time taken: -1.2871310679193009, -0.7854433673506231, 92.39376902580261\n",
      "Item 17010 test r2(pr), test r2(mu), time taken: -0.5025369925672201, -0.4081011297961781, 68.2662706375122\n",
      "Item 17070 test r2(pr), test r2(mu), time taken: -0.6370744128109689, -0.257709945241569, 43.32663440704346\n",
      "Item 17222 test r2(pr), test r2(mu), time taken: -0.011727403991862673, -0.04610190435856931, 38.020676374435425\n",
      "Item 17239 test r2(pr), test r2(mu), time taken: -0.25726545158191305, -0.26094408508629874, 62.095553398132324\n",
      "Item 17247 test r2(pr), test r2(mu), time taken: -0.11093632548593102, -3.6755828418510976, 48.129741191864014\n",
      "Item 17330 test r2(pr), test r2(mu), time taken: -0.18046356343875347, -0.18379887202862077, 30.38765573501587\n",
      "Item 17335 test r2(pr), test r2(mu), time taken: -0.07885788941908789, -0.1582803542694251, 21.80919885635376\n",
      "Item 17340 test r2(pr), test r2(mu), time taken: -0.466660800977275, -0.48107502103692723, 39.932082176208496\n",
      "Item 17341 test r2(pr), test r2(mu), time taken: -0.0896939433182169, -0.08816517020959513, 19.605995893478394\n",
      "Item 17354 test r2(pr), test r2(mu), time taken: -0.10790199559801117, -0.05647952242299725, 41.412458181381226\n",
      "Item 17426 test r2(pr), test r2(mu), time taken: -0.31998873751781143, -0.8501242014158976, 30.485559701919556\n",
      "Item 17442 test r2(pr), test r2(mu), time taken: -0.023297947657280105, -0.00025049331691362475, 37.54313135147095\n",
      "Item 17454 test r2(pr), test r2(mu), time taken: -0.5076458991217887, -0.42159248335853183, 39.844077348709106\n",
      "Item 17482 test r2(pr), test r2(mu), time taken: -1.5577039473802556, -0.5693313154229807, 58.866196632385254\n",
      "Item 17550 test r2(pr), test r2(mu), time taken: -0.3764865596295788, -0.12727416962920346, 28.53264284133911\n",
      "Item 17561 test r2(pr), test r2(mu), time taken: -8.123722464569111, -6.2941303189125986, 32.63248801231384\n",
      "Item 17652 test r2(pr), test r2(mu), time taken: -1.6823649239519125, -0.8364518913335468, 29.082415103912354\n",
      "Item 17749 test r2(pr), test r2(mu), time taken: -0.006337468861071782, -0.039193268651124935, 21.699127197265625\n",
      "Item 17796 test r2(pr), test r2(mu), time taken: -0.14097576061752792, -0.0035755231386582764, 60.24957823753357\n",
      "Item 17841 test r2(pr), test r2(mu), time taken: 0.08196005342504398, 0.04885179030912823, 28.938989877700806\n",
      "Item 17845 test r2(pr), test r2(mu), time taken: 0.030662616150575195, 0.013863738906418233, 25.218977212905884\n",
      "Item 17905 test r2(pr), test r2(mu), time taken: -0.40190888981993145, -0.4048054580030882, 42.68344807624817\n",
      "Item 17923 test r2(pr), test r2(mu), time taken: -0.07659280034794658, -0.10697796669521331, 26.99161720275879\n",
      "Item 18000 test r2(pr), test r2(mu), time taken: -0.3249433537937527, -0.3617556020687094, 25.669819593429565\n",
      "Item 18011 test r2(pr), test r2(mu), time taken: -0.31490002516702975, -0.30259665653371415, 45.46940469741821\n",
      "Item 18039 test r2(pr), test r2(mu), time taken: -0.11289544022682252, -0.15202194202656893, 22.382595539093018\n",
      "Item 18076 test r2(pr), test r2(mu), time taken: -16.902673974667778, -5.011348630880883, 59.993980407714844\n",
      "Item 18109 test r2(pr), test r2(mu), time taken: -0.640804746288465, -0.592367636697263, 30.014612674713135\n",
      "Item 18211 test r2(pr), test r2(mu), time taken: -0.28927347793672187, -0.1288674589636818, 25.255234718322754\n",
      "Item 18237 test r2(pr), test r2(mu), time taken: -0.06437837305773808, -0.19587886955261835, 98.00791001319885\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(columns = [\"rmse_train_transformer_pr\", \"r2_train_transformer_pr\", \"rmse_test_transformer_pr\", \"r2_test_transformer_pr\", \"rmse_train_transformer_mu\", \"r2_train_transformer_mu\", \"rmse_test_transformer_mu\", \"r2_test_transformer_mu\", \"Time Taken\"])\n",
    "prediction_df_1 = pd.DataFrame()\n",
    "prediction_df_1.index = df_validation.index[optimal_sequence_length:]\n",
    "prediction_df_2 = pd.DataFrame()\n",
    "prediction_df_2.index = df_validation.index[optimal_sequence_length:]\n",
    "results = results3\n",
    "\n",
    "for string_i in results.columns: \n",
    "    \n",
    "    i = int(string_i)\n",
    "    start_time = time.time()\n",
    "\n",
    "    original_prediction_residuals_df = df_sales.iloc[optimal_sequence_length:, i] - results[string_i][:-28]\n",
    "    mu = original_prediction_residuals_df.mean()\n",
    "    total_residuals = [mu]*(optimal_sequence_length-1)+list(original_prediction_residuals_df)\n",
    "    total_residuals = np.array(total_residuals).reshape(len(total_residuals), 1)\n",
    "    total_residuals_df = pd.DataFrame(total_residuals)\n",
    "    total_residuals_df.index = df_sales.index[:-1]\n",
    "\n",
    "    y_scaler = MinMaxScaler((-1, 1))\n",
    "    r_scaler = MinMaxScaler((-1, 1))\n",
    "    y_scaler.fit(df_sales.iloc[:, i:i+1].values.reshape(-1, 1))\n",
    "    r_scaler.fit(total_residuals_df.values.reshape(-1, 1))\n",
    "    normalized_y = y_scaler.transform(df_sales.iloc[:-1, i:i+1])\n",
    "    normalized_r = r_scaler.transform(total_residuals_df)\n",
    "    train_data_normalized = np.concatenate([normalized_y, normalized_r], axis=1)\n",
    "    sequences = load_and_partition_data(train_data_normalized, optimal_sequence_length+1)\n",
    "    train_data = torch.tensor(np.array(sequences[:-28]), dtype=torch.float)\n",
    "    val_data = torch.tensor(np.array(sequences[-28:]), dtype=torch.float)\n",
    "    train_loader = DataLoader(train_data, batch_size=optimal_batch_size , shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=optimal_batch_size, shuffle=False, drop_last=False)\n",
    "    ##############################################################  Training  ##########################################################\n",
    "    #####  Parameters  ######################\n",
    "    num_features = len(train_data_normalized[0])\n",
    "    D_MODEL = optimal_d_model  \n",
    "    NUM_HEADS = optimal_num_head \n",
    "    NUM_LAYERS = optimal_num_layer \n",
    "    NUM_EPOCHS = 200\n",
    "    LR = 0.001\n",
    "    #####Init the Model #######################\n",
    "    model = TransformerWithPE(num_features, num_features, D_MODEL, NUM_HEADS, NUM_LAYERS)\n",
    "    model.to(device)\n",
    "    early_stopper = utils.EarlyStopper(patience=20)\n",
    "    ##### Set Criterion Optimzer and scheduler ####################\n",
    "    criterion = torch.nn.MSELoss().to(device)    # mean-squared error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR,weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  patience=20,factor =0.1 ,min_lr=1e-7, eps=1e-08)\n",
    "    # Train the model\n",
    "    train_loss_, val_loss_ = [], []\n",
    "    for epoch in range(NUM_EPOCHS): \n",
    "        train_loss, val_loss = 0, 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "            pred = model(src.to(device), tgt.to(device))\n",
    "            loss = criterion(pred, tgt_y.to(device))\n",
    "            train_loss += loss.item()\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss/=len(train_loader.dataset)\n",
    "        train_loss_.append(train_loss)\n",
    "        #Evaluate on test     \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                src, tgt, tgt_y = split_sequence(batch, optimal_sequence_length/(optimal_sequence_length+1))\n",
    "                val = model(src.to(device), tgt.to(device))\n",
    "                loss = criterion(val, tgt_y.to(device))\n",
    "                val_loss += loss.item()\n",
    "        val_loss/=len(val_loader.dataset)\n",
    "        val_loss_.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "        if early_stopper.early_stop(val_loss, model, 'Models/transformer_final_w_residuals.pth'):\n",
    "            early_stopped = epoch+1\n",
    "            break\n",
    "    ##############################################################  Testing 1  ##########################################################        break\n",
    "    model = torch.load('Models/transformer_final_w_residuals.pth')\n",
    "    sequences_tensor = Variable(torch.Tensor(sequences))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src, tgt, tgt_y = split_sequence(sequences_tensor, 28/29)\n",
    "        predicts_ = model(src.to(device), tgt.to(device))\n",
    "    predicts_ = predicts_.cpu().numpy().reshape(-1, 2)\n",
    "    forecasts_ = np.zeros((28, 2))\n",
    "    src = train_data_normalized[-optimal_sequence_length:]\n",
    "    src = Variable(torch.Tensor(src)).unsqueeze(0)\n",
    "    tgt_len = 1\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        forecasted = model.infer(src.to(device), tgt_len)\n",
    "    predicts_ = np.concatenate([predicts_, forecasted.cpu().data.numpy()[0]])\n",
    "    forecasted[0][0][0] = y_scaler.transform([[df_sales.iloc[-1, i]]])[0][0]\n",
    "    for j in range(28):\n",
    "        src = torch.cat((src[:, 1:].to(device), forecasted), dim = 1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecasted = model.infer(src.to(device), tgt_len)\n",
    "        forecasts_[j][0] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "        forecasts_[j][1] = forecasted.cpu().data.numpy()[0][0][1]\n",
    "    all_prediction = np.append(predicts_[:, 0], forecasts_[:, 0])\n",
    "\n",
    "    sales_validation = pd.DataFrame(df_validation.iloc[:,i])\n",
    "    \n",
    "    prediction_df_1[i] = y_scaler.inverse_transform(np.array(all_prediction).reshape(-1, 1)).reshape(-1)\n",
    "    rmse_train_lstm_1 = np.sqrt(mean_squared_error(sales_validation[optimal_sequence_length:-28], prediction_df_1.iloc[:-28][i]))\n",
    "    r2_train_lstm_1 = r2_score(sales_validation[optimal_sequence_length:-28], prediction_df_1.iloc[:-28][i])\n",
    "    rmse_test_lstm_1 = np.sqrt(mean_squared_error(sales_validation[-28:], prediction_df_1.iloc[-28:][i]))\n",
    "    r2_test_lstm_1 = r2_score(sales_validation[-28:], prediction_df_1.iloc[-28:][i])\n",
    "    ##############################################################  Testing 2  ##########################################################\n",
    "    sequences_tensor = Variable(torch.Tensor(sequences))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src, tgt, tgt_y = split_sequence(sequences_tensor, 28/29)\n",
    "        predicts_ = model(src.to(device), tgt.to(device))\n",
    "    predicts_ = predicts_.cpu().numpy().reshape(-1, 2)\n",
    "    forecasts_ = np.zeros((28, 2))\n",
    "    src = train_data_normalized[-optimal_sequence_length:]\n",
    "    src = Variable(torch.Tensor(src)).unsqueeze(0)\n",
    "    tgt_len = 1\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        forecasted = model.infer(src.to(device), tgt_len)\n",
    "    predicts_ = np.concatenate([predicts_, forecasted.cpu().data.numpy()[0]])\n",
    "    forecasted[0][0][0] = y_scaler.transform([[df_sales.iloc[-1, i]]])[0][0]\n",
    "    for j in range(28):\n",
    "        forecasted[0][0][1] = torch.tensor(r_scaler.transform([[mu]])[0][0]).to(device)\n",
    "        src = torch.cat((src[:, 1:].to(device), forecasted), dim = 1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecasted = model.infer(src.to(device), tgt_len)\n",
    "        forecasts_[j][0] = forecasted.cpu().data.numpy()[0][0][0]\n",
    "        forecasts_[j][1] = forecasted.cpu().data.numpy()[0][0][1]\n",
    "    all_prediction = np.append(predicts_[:, 0], forecasts_[:, 0])\n",
    "    \n",
    "    prediction_df_2[i] = y_scaler.inverse_transform(np.array(all_prediction).reshape(-1, 1)).reshape(-1)\n",
    "    rmse_train_lstm_2 = np.sqrt(mean_squared_error(sales_validation[optimal_sequence_length:-28], prediction_df_2.iloc[:-28][i]))\n",
    "    r2_train_lstm_2 = r2_score(sales_validation[optimal_sequence_length:-28], prediction_df_2.iloc[:-28][i])\n",
    "    rmse_test_lstm_2 = np.sqrt(mean_squared_error(sales_validation[-28:], prediction_df_2.iloc[-28:][i]))\n",
    "    r2_test_lstm_2 = r2_score(sales_validation[-28:], prediction_df_2.iloc[-28:][i])\n",
    "    time_taken = time.time() - start_time\n",
    "\n",
    "    summary_df.loc[i] = [rmse_train_lstm_1, r2_train_lstm_1, rmse_test_lstm_1, r2_test_lstm_1, rmse_train_lstm_2, r2_train_lstm_2, rmse_test_lstm_2, r2_test_lstm_2, time_taken]    \n",
    "    print(f\"Item {i} test r2(pr), test r2(mu), time taken: {r2_test_lstm_1}, {r2_test_lstm_2}, {time_taken}\")\n",
    "\n",
    "summary_df.to_csv(\"Transformer_error_modelling_Summary_3.csv\")\n",
    "prediction_df_1.to_csv(\"Transformer_error_modelling_Results_3_1.csv\")\n",
    "prediction_df_2.to_csv(\"Transformer_error_modelling_Results_3_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259f35f-9dc6-48c8-b3ea-f556ffcf3a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
